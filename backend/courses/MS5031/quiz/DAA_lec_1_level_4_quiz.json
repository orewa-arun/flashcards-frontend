{
  "metadata": {
    "generated_at": "2025-11-04T10:31:01.658882",
    "total_questions": 13,
    "course_name": "Data Analysis Applications",
    "course_id": "MS5031",
    "course_code": "DAA",
    "textbook_reference": "Statistics for Business: Decision Making and Analysis by Robert E Stine and Dean Foster, Pearson (ISBN: 978-81-317-3347-9)",
    "lecture": "DAA_lec_1",
    "difficulty_level": 4,
    "source_flashcards": 6
  },
  "questions": [
    {
      "type": "mcq",
      "question_text": "A data science team at a marketing firm is building a model to predict customer spending based on their age. They create a scatter plot of spending vs. age and notice a slight curve, but initially proceed without any data transformation. The resulting model has a low R-squared value and the residual plot shows a clear pattern: the residuals are mostly positive for young and old customers, and mostly negative for middle-aged customers. To improve the model, the team considers several approaches. Synthesizing the concepts of point prediction (Lec 1) and data transformation (Lec 1), which of the following actions is most likely to improve the *accuracy* and *reliability* of their spending predictions, and why?",
      "visual_type": "None",
      "visual_code": "",
      "alt_text": "",
      "options": {
        "A": "Apply a linear regression model to the original data and use the resulting equation to generate point predictions for customer spending. Since the team needs specific spending estimates for budgeting, a simple model is sufficient.",
        "B": "Apply a polynomial regression model (e.g., quadratic) to the original data to capture the curvature in the relationship between age and spending, and then use this model to generate point predictions. This directly addresses the non-linear relationship.",
        "C": "Apply a logarithmic transformation to the spending data to normalize the distribution and then fit a linear regression model. This will ensure more accurate point predictions by reducing the influence of outliers.",
        "D": "Apply a logarithmic transformation to the age data and an inverse transformation to the spending data before fitting a linear regression model. After obtaining the regression equation, generate point predictions and back-transform the results to the original scale for interpretation."
      },
      "correct_answer": [
        "B"
      ],
      "explanation": "This question synthesizes point prediction (Lec 1) and data transformation (Lec 1). The problem is that a linear model isn't adequate for the curved relationship. Option A fails to address the non-linearity, leading to inaccurate point predictions. Option C only transforms the spending data, which may not fully address the issue of non-linearity between age and spending. Option D is overly complex and potentially unnecessary; also, spending data might contain zero values, making the inverse transformation problematic. Option B correctly identifies that a polynomial regression model can directly capture the curvature and improve the accuracy of point predictions by better fitting the data.",
      "difficulty_level": 4,
      "source_flashcard_id": "DAA_lec_1_1",
      "tags": [
        "regression",
        "point prediction",
        "data transformation",
        "linear regression",
        "non-linear relationships"
      ]
    },
    {
      "type": "mcq",
      "question_text": "An e-commerce company is using a regression model to predict daily sales ($Y$) based on website traffic ($X$). They notice that the variance of the residuals increases as website traffic increases (heteroscedasticity). Initial attempts to improve the model by including additional features (e.g., seasonality, promotions) do not resolve the heteroscedasticity. The team decides to apply a Box-Cox transformation to stabilize the variance. They use the model to make point predictions. Synthesizing the concepts of heteroscedasticity, data transformation (Lec 1), and point prediction (Lec 1), which of the following represents the *most complete* approach to address this issue and generate reliable sales forecasts?",
      "visual_type": "None",
      "visual_code": "",
      "alt_text": "",
      "options": {
        "A": "Apply a logarithmic transformation to only the independent variable ($X$), website traffic. This stabilizes the variance and allows for more accurate point predictions.",
        "B": "Apply a logarithmic transformation to only the dependent variable ($Y$), daily sales, and fit a linear regression model. After generating point predictions using the transformed model, back-transform the predictions to the original scale to obtain the sales forecast. This focuses on stabilizing the variance of the dependent variable, which is the primary concern.",
        "C": "Apply a square root transformation to the dependent variable ($Y$), daily sales, fit a linear regression model, generate point predictions, and back-transform them to the original scale. This is a simpler transformation than logarithmic but equally effective.",
        "D": "Apply a Box-Cox transformation to the dependent variable ($Y$), daily sales, fit a linear regression model, generate point predictions using the transformed model, back-transform the predictions to the original scale, and then evaluate the residual plot to confirm that heteroscedasticity has been sufficiently reduced. If not, iterate with a different transformation parameter within the Box-Cox framework."
      },
      "correct_answer": [
        "D"
      ],
      "explanation": "This question synthesizes heteroscedasticity, data transformation, and point prediction. The most complete approach involves applying a Box-Cox transformation to the dependent variable (daily sales), fitting a linear regression model, generating point predictions, back-transforming the predictions, and *critically* evaluating the residual plot to confirm the heteroscedasticity is sufficiently addressed. Option A only transforms the independent variable. Option B only transforms the dependent variable and back-transforms, but lacks the critical step of evaluating the residuals *after* the transformation. Option C uses a specific square root transformation, which may not be optimal; it also omits the residual plot evaluation. Option D is the most comprehensive because it includes the crucial step of verifying the transformation's effectiveness through residual analysis.",
      "difficulty_level": 4,
      "source_flashcard_id": "DAA_lec_1_2",
      "tags": [
        "data transformation",
        "linear regression",
        "heteroscedasticity",
        "point prediction"
      ]
    },
    {
      "type": "mcq",
      "question_text": "A bio-pharmaceutical company is conducting research to understand the dose-response relationship of a novel drug. They hypothesize that the drug's effect on reducing tumor size diminishes as the dosage increases beyond a certain point. They collect data on drug dosage ($X$) and tumor size reduction ($Y$). A scatter plot reveals a curved relationship where increasing dosage leads to a rapid reduction in tumor size initially, but the effect plateaus at higher dosages. A linear regression model shows a poor fit. The research team needs to decide on an appropriate transformation strategy to linearize the relationship. Synthesizing the concepts of inverse transformation (Lec 1) and logarithmic transformation (Lec 1), which transformation is more appropriate in this scenario, and why?",
      "visual_type": "None",
      "visual_code": "",
      "alt_text": "",
      "options": {
        "A": "Apply a logarithmic transformation to the drug dosage ($X$) because it is known to linearize exponential relationships, and drug effects are often exponential.",
        "B": "Apply an inverse transformation to the drug dosage ($X$) because it can model diminishing returns, where the effect of increasing the dosage decreases as the dosage gets larger.",
        "C": "Apply a logarithmic transformation to the tumor size reduction ($Y$) because it will normalize the distribution and improve the model's overall fit.",
        "D": "Apply a quadratic transformation to the drug dosage ($X$) to model the initial increase in effectiveness followed by a plateau."
      },
      "correct_answer": [
        "B"
      ],
      "explanation": "This question synthesizes inverse and logarithmic transformations to model a diminishing returns scenario. Option A is incorrect because a logarithmic transformation is typically used for exponential growth or decreasing rates of return, not diminishing returns. Option C focuses on normalizing the distribution of the dependent variable, but the primary issue is the non-linear relationship. Option D, while potentially useful, doesn't directly address the diminishing returns aspect as effectively as an inverse transformation. Option B is the most appropriate because it correctly identifies that an inverse transformation of the drug dosage will model the diminishing returns effect, where increasing the dosage has a smaller and smaller impact on tumor size reduction as the dosage increases.",
      "difficulty_level": 4,
      "source_flashcard_id": "DAA_lec_1_4",
      "tags": [
        "inverse transformation",
        "logarithmic transformation",
        "regression analysis",
        "asymptotic relationship",
        "linearization"
      ]
    },
    {
      "type": "mcq",
      "question_text": "An environmental agency is studying the relationship between industrial waste discharge ($X$) and river water quality ($Y$). They hypothesize that as waste discharge increases, water quality decreases rapidly at first, but the rate of decrease slows down as the river becomes more polluted. A scatter plot of the data shows a curve approaching an asymptote, where further increases in waste discharge have a diminishing impact on water quality. The agency needs to build a regression model to predict water quality based on waste discharge. The agency is also concerned about the interpretability of the results for policy makers. Synthesizing the concepts of data transformation (Lec 1) and regression coefficient interpretation (Lec 2), which transformation strategy would be most appropriate considering *both* the statistical fit *and* the ease of interpretation for non-technical stakeholders?",
      "visual_type": "None",
      "visual_code": "",
      "alt_text": "",
      "options": {
        "A": "Apply a Box-Cox transformation to the water quality data ($Y$) to optimize the model fit, regardless of the interpretability of the transformed coefficients. Focus on prediction accuracy above all else.",
        "B": "Apply an inverse transformation to the waste discharge data ($X$). This will linearize the relationship and the coefficients will represent the change in water quality per unit *decrease* in the inverse of waste discharge, which is still relatively interpretable.",
        "C": "Apply a logarithmic transformation to both waste discharge ($X$) and water quality ($Y$). This will linearize the relationship and the coefficients will represent percentage changes, making it easier to communicate the impact to policy makers.",
        "D": "Apply a simple linear regression model to the original data without any transformation, and acknowledge the limitations of the model fit. This ensures that the coefficients are directly interpretable in their original units, facilitating communication."
      },
      "correct_answer": [
        "B"
      ],
      "explanation": "This question synthesizes data transformation and regression coefficient interpretation. The scenario involves a diminishing returns relationship best modeled by an inverse transformation. Option A prioritizes model fit over interpretability, which is problematic given the need to communicate with policy makers. Option C, while offering percentage changes, might obscure the specific impact of *decreasing* water quality due to *increasing* waste discharge, which is the key concern. Option D sacrifices model accuracy for the sake of interpretability, which is not ideal. Option B is the most appropriate because it applies an inverse transformation to waste discharge, which linearizes the relationship while maintaining relatively straightforward interpretability. The coefficients will indicate the change in water quality per unit *decrease* in the inverse of waste discharge, which can be explained as the diminishing impact of waste discharge on water quality as waste discharge increases. This balances statistical fit and ease of understanding.",
      "difficulty_level": 4,
      "source_flashcard_id": "DAA_lec_1_4",
      "tags": [
        "inverse transformation",
        "regression analysis",
        "asymptotic relationship",
        "linearization",
        "regression coefficient interpretation"
      ]
    },
    {
      "type": "mcq",
      "question_text": "A telecommunications company is analyzing the relationship between the number of cell towers ($X$) in a region and the average data download speed ($Y$) experienced by users. They observe that adding more cell towers initially leads to a rapid increase in download speed, but the improvement diminishes as the number of towers increases, due to factors like signal interference and network congestion. The data exhibits a curve approaching an asymptote. They want to predict download speed for different cell tower deployments and are also concerned about accurately estimating the uncertainty around these predictions. Synthesizing the concepts of inverse transformation (Lec 1) and confidence intervals (Lec 3), which approach would be most appropriate to both linearize the relationship and provide reliable estimates of prediction uncertainty?",
      "visual_type": "None",
      "visual_code": "",
      "alt_text": "",
      "options": {
        "A": "Apply a logarithmic transformation to the download speed data ($Y$), fit a linear regression model, calculate confidence intervals for the predicted download speeds in the transformed scale, and then back-transform the confidence interval limits to the original scale. This ensures the confidence intervals are also linearized.",
        "B": "Apply an inverse transformation to the number of cell towers ($X$), fit a linear regression model, calculate confidence intervals for the predicted download speeds in the original scale, and interpret these intervals directly. This focuses on linearizing the independent variable and providing interpretable confidence intervals.",
        "C": "Apply a Box-Cox transformation to the download speed data ($Y$), fit a linear regression model, calculate confidence intervals for the predicted download speeds in the transformed scale, back-transform both the point predictions and the confidence interval limits to the original scale, and then verify the coverage probability of the resulting intervals. This provides the most statistically valid confidence intervals after transformation.",
        "D": "Apply a simple linear regression model to the original data without any transformation. Calculate confidence intervals for the predicted download speeds, but acknowledge that these intervals may be less accurate due to the non-linear relationship."
      },
      "correct_answer": [
        "C"
      ],
      "explanation": "This question synthesizes inverse transformation and confidence intervals. The key is to both linearize the relationship *and* ensure the validity of the confidence intervals after transformation. Option A only transforms the dependent variable and back-transforms the confidence interval limits, which may not fully address the non-linearity in the relationship between cell towers and download speed. Option B linearizes the independent variable but doesn't account for the potential impact of the transformation on the distribution of errors when calculating confidence intervals. Option D avoids transformation altogether, leading to potentially inaccurate confidence intervals. Option C is the most appropriate because it uses a Box-Cox transformation (or similar appropriate transformation) to linearize the relationship, calculates confidence intervals in the transformed scale, back-transforms both the predictions and interval limits, and *crucially* validates the coverage probability of the resulting confidence intervals. This ensures that the confidence intervals are statistically valid after the transformation, providing reliable estimates of prediction uncertainty.",
      "difficulty_level": 4,
      "source_flashcard_id": "DAA_lec_1_4",
      "tags": [
        "inverse transformation",
        "regression analysis",
        "asymptotic relationship",
        "linearization",
        "confidence intervals"
      ]
    },
    {
      "type": "mcq",
      "question_text": "An agricultural research firm is studying the impact of a new fertilizer on soybean yield. Initial tests show that increasing fertilizer application significantly boosts yield. However, some agronomists believe that excessive fertilizer can be detrimental, leading to reduced yields due to nutrient burn and soil salinity. They collect data on fertilizer application (in kg/hectare) and soybean yield (in tonnes/hectare) across 50 test plots. A statistician fits a quadratic model to the data and obtains the following equation: $\\hat{Y} = 2.5 + 0.8X - 0.03X^2$, where Y is the yield and X is the fertilizer application.  The firm's marketing department proposes a simple campaign: 'The more fertilizer, the better the yield!'. Considering the quadratic model and potential overfitting (Lecture 1.5) alongside the importance of data visualization and model checking (Lecture 1.6), what is the most appropriate course of action?",
      "visual_type": "None",
      "visual_code": "",
      "alt_text": "",
      "options": {
        "A": "Launch the 'more is better' marketing campaign immediately, as the positive coefficient on X indicates a direct relationship between fertilizer and yield.",
        "B": "Conduct further residual analysis and visualize the data to check the quadratic model's fit and potential overfitting before launching any marketing campaign. Additionally, determine the fertilizer level that maximizes yield based on the quadratic model.",
        "C": "Recommend applying the maximum amount of fertilizer possible based on the firm's capacity, as this will ensure the highest possible soybean yield.",
        "D": "Fit a higher-degree polynomial model (e.g., cubic or quartic) to the data to capture any additional complexity in the relationship between fertilizer and yield, and then launch the 'more is better' campaign."
      },
      "correct_answer": [
        "B"
      ],
      "explanation": "This is a synthesis question integrating the quadratic model (Lecture 1.5) and the regression process (Lecture 1.6). Option A is flawed because it ignores the negative coefficient on the quadratic term and the potential for diminishing returns or negative effects. Option C ignores the model entirely and makes an unsupported claim. Option D suggests overfitting the data with an even more complex model without proper validation. The correct answer recognizes the importance of validating the quadratic model's fit through residual analysis and visualization, and also suggests finding the optimal fertilizer level predicted by the model. The trade-off is between maximizing yield and avoiding over-fertilization, which the correct answer addresses by finding the optimal point.",
      "difficulty_level": 4,
      "source_flashcard_id": "DAA_lec_1_5",
      "tags": [
        "polynomial transformation",
        "quadratic model",
        "curvilinear relationship",
        "regression process",
        "model fitting",
        "prediction",
        "transformation"
      ]
    },
    {
      "type": "mcq",
      "question_text": "A retail company is analyzing the relationship between online advertising spend ($X$) and website traffic ($Y$). They suspect that the relationship is curvilinear: initially, increasing ad spend leads to a large increase in traffic, but as ad spend increases further, the marginal increase in traffic diminishes due to ad fatigue and market saturation.  They fit a quadratic model and obtain the following equation: $\\hat{Y} = 100 + 5X - 0.1X^2$. However, the marketing director notices that the R-squared value is relatively low (0.55), indicating a poor fit.  The data scientist suggests a logarithmic transformation on both X and Y to potentially improve the model fit and capture the diminishing returns effect more accurately. Considering the trade-offs between model complexity (Lecture 1.5) and model fit and interpretation (Lecture 1.6), which approach is most reasonable?",
      "visual_type": "None",
      "visual_code": "",
      "alt_text": "",
      "options": {
        "A": "Immediately abandon the quadratic model and fit a linear model, as simpler models are always preferable when R-squared is low.",
        "B": "Proceed with the logarithmic transformation on both X and Y, and carefully interpret the transformed coefficients. Compare the R-squared and residual plots of both the quadratic model and the log-log model to determine which provides a better fit.",
        "C": "Fit a high-degree polynomial model (e.g., a 5th-degree polynomial) to achieve a higher R-squared, as this will guarantee a better model.",
        "D": "Ignore the low R-squared and continue using the quadratic model, as it already captures the curvilinear relationship."
      },
      "correct_answer": [
        "B"
      ],
      "explanation": "This question synthesizes polynomial transformations (Lecture 1.5) and the regression process, including transformations and model assessment (Lecture 1.6). Option A is incorrect because a low R-squared doesn't automatically mean a linear model is better; the curvilinear relationship might be real but not well captured by the quadratic. Option C is a classic case of overfitting. Option D ignores the diagnostic information provided by the low R-squared. The correct answer suggests a reasonable alternative (log-log transformation) and emphasizes the importance of comparing model fit using both R-squared and residual plots. The trade-off is between capturing the curvature (quadratic) and potentially achieving a better fit and easier interpretation (log-log). The correct answer advocates for informed model selection based on empirical evidence.",
      "difficulty_level": 4,
      "source_flashcard_id": "DAA_lec_1_5",
      "tags": [
        "polynomial transformation",
        "quadratic model",
        "curvilinear relationship",
        "regression process",
        "model fitting",
        "prediction",
        "transformation"
      ]
    },
    {
      "type": "mcq",
      "question_text": "A data scientist is building a model to predict customer churn for a telecommunications company. They hypothesize that customer satisfaction ($X_1$) has a negative linear relationship with churn, and contract length ($X_2$) also has a negative linear relationship. However, they also suspect that very short or very long contract lengths might actually *increase* churn due to different reasons (e.g., short contracts offer flexibility to switch, long contracts might lead to dissatisfaction if needs change).  They initially fit a multiple linear regression model, but a colleague suggests adding a quadratic term for contract length ($X_2^2$) to capture the potential U-shaped relationship.  Considering model complexity (Lecture 1.5) and the overall regression process (Lecture 1.6), what is the most critical aspect to consider before adding the quadratic term?",
      "visual_type": "None",
      "visual_code": "",
      "alt_text": "",
      "options": {
        "A": "Ensure that the coefficients for both $X_1$ and $X_2$ are statistically significant in the linear model before considering any transformations.",
        "B": "Visually inspect the relationship between contract length ($X_2$) and churn using a scatterplot or other visualization technique to confirm the U-shaped pattern before adding the quadratic term.",
        "C": "Immediately add the quadratic term, as it will always improve the model's R-squared value.",
        "D": "Remove the customer satisfaction variable ($X_1$) from the model to simplify the analysis."
      },
      "correct_answer": [
        "B"
      ],
      "explanation": "This question requires synthesizing knowledge of polynomial transformations (Lecture 1.5) and the regression process (Lecture 1.6). Option A is important but doesn't directly address the question of whether to add a quadratic term. Option C is incorrect because adding a quadratic term doesn't *always* improve the model, and it can lead to overfitting. Option D is an arbitrary simplification that could remove important information. The correct answer emphasizes the importance of *visualizing the data* to confirm the hypothesized U-shaped relationship *before* adding the quadratic term. This prevents blindly adding complexity without empirical justification. The question highlights the importance of data exploration as a prerequisite to model building.",
      "difficulty_level": 4,
      "source_flashcard_id": "DAA_lec_1_5",
      "tags": [
        "polynomial transformation",
        "quadratic model",
        "curvilinear relationship",
        "regression process",
        "model fitting",
        "prediction",
        "transformation"
      ]
    },
    {
      "type": "mcq",
      "question_text": "An e-commerce company is analyzing the relationship between the number of promotional emails sent per month ($X$) and the total revenue generated ($Y$). They hypothesize that sending more emails initially increases revenue, but beyond a certain point, customers get annoyed, unsubscribe, and revenue declines. They fit a quadratic model: $\\hat{Y} = 1000 + 50X - 2X^2$. The marketing team wants to know the optimal number of emails to send to maximize revenue. However, the data scientist also knows that email deliverability decreases as the number of emails sent increases due to spam filters and ISP restrictions. This means that sending a very high number of emails might not even reach customers, regardless of the model's prediction. Considering the quadratic model (Lecture 1.5) and the limitations and interpretations in the regression process (Lecture 1.6), what is the most effective strategy?",
      "visual_type": "None",
      "visual_code": "",
      "alt_text": "",
      "options": {
        "A": "Calculate the number of emails that maximizes the quadratic model and send that many emails to all customers.",
        "B": "Calculate the number of emails that maximizes the quadratic model. Then, conduct A/B testing with different email frequencies around that optimal point, measuring both revenue and email deliverability rates.  Adjust the email frequency based on the A/B test results to account for deliverability.",
        "C": "Ignore the quadratic model and send the maximum number of emails possible, as this will reach the most customers and likely generate the most revenue.",
        "D": "Fit a higher-degree polynomial model to better capture the relationship between email frequency and revenue."
      },
      "correct_answer": [
        "B"
      ],
      "explanation": "This question combines the quadratic model (Lecture 1.5) with the regression process and its limitations (Lecture 1.6). Option A ignores the deliverability issue, which is a crucial real-world constraint. Option C is based on a flawed assumption and ignores the potential for diminishing returns and customer annoyance. Option D suggests overfitting the model. The correct answer acknowledges the model's prediction but also recognizes the importance of validating it with A/B testing and considering the practical constraint of email deliverability. The correct response understands that the quadratic model provides a starting point but that real-world factors need to be incorporated through experimentation and monitoring. It's a synthesis of model-based prediction and empirical validation.",
      "difficulty_level": 4,
      "source_flashcard_id": "DAA_lec_1_5",
      "tags": [
        "polynomial transformation",
        "quadratic model",
        "curvilinear relationship",
        "regression process",
        "model fitting",
        "prediction",
        "transformation"
      ]
    },
    {
      "type": "mcq",
      "question_text": "A pharmaceutical company is developing a new drug to treat hypertension. They conduct a clinical trial with varying dosages of the drug (in mg) and measure the reduction in systolic blood pressure (in mmHg). Initial results show a positive effect: increasing the dosage leads to a greater reduction in blood pressure. However, they also suspect that very high dosages might lead to adverse side effects, potentially negating the benefits. They fit a quadratic model to the data: $\\hat{Y} = 5 + 2X - 0.05X^2$, where Y is the reduction in blood pressure and X is the dosage.  The company's regulatory affairs department is primarily concerned with minimizing potential side effects, even if it means slightly reducing the overall effectiveness of the drug.  The R&D team is focused on maximizing the reduction in blood pressure, while staying within acceptable safety limits. The statistician must balance these competing objectives.  Synthesizing the knowledge about the quadratic model from Lecture 1.5 with the entire regression process from Lecture 1.6, what is the most statistically sound and ethically responsible approach?",
      "visual_type": "None",
      "visual_code": "",
      "alt_text": "",
      "options": {
        "A": "Calculate the dosage that maximizes the reduction in blood pressure based on the quadratic model and recommend that dosage for all patients, regardless of potential side effects.",
        "B": "Calculate the dosage that maximizes the reduction in blood pressure based on the quadratic model. Then, conduct further analysis to estimate the probability of side effects at different dosages. Recommend a dosage that balances the reduction in blood pressure with an acceptable risk of side effects, as defined by the regulatory affairs department.",
        "C": "Fit a linear model to the data, as this will minimize the potential for overfitting and provide a simpler, more conservative estimate of the drug's effectiveness.",
        "D": "Ignore the quadratic model and recommend the highest possible dosage that can be manufactured, as this will likely lead to the greatest reduction in blood pressure."
      },
      "correct_answer": [
        "B"
      ],
      "explanation": "This question synthesizes the quadratic model (Lecture 1.5) with the regression process (Lecture 1.6), emphasizing the importance of interpretation and real-world constraints. Option A ignores the crucial issue of side effects and the regulatory constraints. Option C is an oversimplification that could miss the true relationship between dosage and blood pressure reduction. Option D is ethically irresponsible. The correct answer acknowledges the model's prediction but also recognizes the need to balance effectiveness with safety. It suggests a comprehensive approach that involves both statistical modeling and risk assessment, incorporating the regulatory constraints. The trade-off is between maximizing drug effectiveness and minimizing side effects, and the correct answer provides a framework for making that trade-off in a responsible manner. The ethical dimension adds complexity to the statistical analysis.",
      "difficulty_level": 4,
      "source_flashcard_id": "DAA_lec_1_5",
      "tags": [
        "polynomial transformation",
        "quadratic model",
        "curvilinear relationship",
        "regression process",
        "model fitting",
        "prediction",
        "transformation"
      ]
    },
    {
      "type": "mcq",
      "question_text": "A data analyst is tasked with predicting monthly sales for a retail store based on several factors: advertising spend ($X_1$), number of promotions run ($X_2$), and the average daily temperature ($X_3$). They start by visualizing the data and notice a non-linear relationship between temperature and sales: sales increase with temperature up to a certain point, then decline during extreme heat. They decide to incorporate a quadratic term for temperature ($X_3^2$) in their multiple regression model. After fitting the model, they notice that while the model fits the training data well, its performance on a holdout set is significantly worse. Considering the need for transformation and understanding the overall regression process (Lecture 1.6), what is the most likely cause of this discrepancy and what action should be taken?",
      "visual_type": "None",
      "visual_code": "",
      "alt_text": "",
      "options": {
        "A": "The most likely cause is multicollinearity between $X_3$ and $X_3^2$. To address this, remove the original temperature variable ($X_3$) from the model, leaving only the quadratic term.",
        "B": "The most likely cause is overfitting due to the added complexity of the quadratic term. To address this, consider using regularization techniques (e.g., Ridge or Lasso regression) or simplify the model by removing the quadratic term and potentially other less important variables.",
        "C": "The most likely cause is insufficient data. To address this, collect more data and refit the model.",
        "D": "The most likely cause is a coding error. To address this, meticulously review the code for errors."
      },
      "correct_answer": [
        "B"
      ],
      "explanation": "This question synthesizes understanding of the regression process, particularly model fitting and prediction (Lecture 1.6), with the potential for overfitting when using polynomial transformations (Lecture 1.5). Option A, while multicollinearity *can* be a problem, doesn't address the core issue of overfitting. Removing the linear term and only using the quadratic would likely worsen the model's ability to predict the *increasing* portion of the curve. Option C (collecting more data) *could* help, but it doesn't address the immediate problem of overfitting with the *current* data. Option D (coding error) is a general troubleshooting step but isn't the *most likely* explanation given the scenario. The correct answer directly addresses the issue of overfitting by suggesting regularization or simplification. Regularization adds a penalty for model complexity, while removing the quadratic term directly reduces complexity. The trade-off is between model fit and model generalizability, and the correct answer prioritizes generalizability to unseen data.",
      "difficulty_level": 4,
      "source_flashcard_id": "DAA_lec_1_6",
      "tags": [
        "regression process",
        "model fitting",
        "prediction",
        "transformation",
        "polynomial transformation",
        "quadratic model",
        "curvilinear relationship"
      ]
    },
    {
      "type": "mcq",
      "question_text": "A marketing analyst at a subscription-based streaming service is building a model to predict customer churn. They have data on various customer attributes, including monthly viewing hours ($X_1$), number of devices connected ($X_2$), and customer tenure (in months, $X_3$). They hypothesize that customers with very short or very long tenures are more likely to churn (U-shaped relationship). They include a quadratic term for tenure ($X_3^2$) in their regression model. The model shows a statistically significant relationship between all predictors and churn.  The analyst now needs to present the model's findings to the non-technical marketing team.  Given the need to interpret the regression results effectively (Lecture 1.6) and the complexities of polynomial models (Lecture 1.5), what is the most accurate and understandable way to explain the impact of customer tenure on churn?",
      "visual_type": "None",
      "visual_code": "",
      "alt_text": "",
      "options": {
        "A": "Simply state the coefficients for $X_3$ and $X_3^2$ and explain that a positive coefficient for $X_3^2$ indicates a U-shaped relationship.",
        "B": "Create a scatterplot of tenure vs. churn and overlay the predicted churn values from the model across the range of tenure values. Explain that the graph shows how churn initially decreases with tenure but then increases again for longer tenures.",
        "C": "Only focus on the linear term for tenure ($X_3$) and ignore the quadratic term, as it is too complex to explain to a non-technical audience.",
        "D": "Randomly select a subset of customers and explain how the model predicts their churn probability based solely on their tenure."
      },
      "correct_answer": [
        "B"
      ],
      "explanation": "This question synthesizes the overall regression process (Lecture 1.6), with a focus on interpretation, and the complexities of polynomial models (Lecture 1.5). Option A is technically correct but highly unintuitive for a non-technical audience. Option C ignores a key aspect of the model (the quadratic term) and misrepresents the relationship. Option D is not a generalizable explanation. The correct answer provides a *visual* representation of the relationship, making it easier for the marketing team to understand the U-shaped effect of tenure on churn. It bridges the gap between the statistical model and actionable insights. The key insight is that the *visualization* of the model's predictions is often more effective than simply presenting the coefficients.",
      "difficulty_level": 4,
      "source_flashcard_id": "DAA_lec_1_6",
      "tags": [
        "regression process",
        "model fitting",
        "prediction",
        "transformation",
        "polynomial transformation",
        "quadratic model",
        "curvilinear relationship"
      ]
    },
    {
      "type": "mcq",
      "question_text": "A real estate company is building a model to predict house prices in a specific city. They have data on house size (in square feet, $X_1$), number of bedrooms ($X_2$), and location score (ranging from 1 to 10, $X_3$). They hypothesize that the relationship between location score and price is non-linear: houses in average locations are more differentiated by other factors (size, bedrooms) than houses in the best or worst locations. They consider including a quadratic term for location score ($X_3^2$). After fitting the initial multiple regression model (without the quadratic term), they find that the residuals show a pattern â€“ they are smaller for houses with average location scores and larger for houses in the best and worst locations. Given what you know about fitting a regression model (Lecture 1.6) and the use of transformations (Lecture 1.5), what is the most appropriate next step to address the observed residual pattern?",
      "visual_type": "None",
      "visual_code": "",
      "alt_text": "",
      "options": {
        "A": "Immediately add the quadratic term for location score ($X_3^2$) to the model, as this will directly address the non-linear relationship and improve the residual pattern.",
        "B": "Apply a variance-stabilizing transformation (e.g., a logarithmic transformation) to the house price variable ($Y$) to address the heteroscedasticity indicated by the residual pattern. Then, refit the model (potentially including the quadratic term for location score).",
        "C": "Remove the location score variable ($X_3$) from the model, as it appears to be causing the heteroscedasticity.",
        "D": "Conclude that the model is adequate, as it already includes the most important predictors of house price."
      },
      "correct_answer": [
        "B"
      ],
      "explanation": "This question integrates the regression process, especially model diagnostics (Lecture 1.6), with the use of transformations, including polynomial transformations (Lecture 1.5). Option A addresses the non-linearity but ignores the heteroscedasticity (non-constant variance) revealed by the residual pattern. Addressing heteroscedasticity is often a priority because it violates a key assumption of linear regression. Option C removes an important predictor. Option D ignores the model diagnostics, which is a critical mistake. The correct answer recognizes that the residual pattern indicates heteroscedasticity, which needs to be addressed *before* focusing solely on the non-linearity. A variance-stabilizing transformation (e.g., log transformation) can often reduce heteroscedasticity, allowing for a more reliable model fit. The key insight is that addressing the *assumptions* of linear regression is often a prerequisite to adding complexity to the model.",
      "difficulty_level": 4,
      "source_flashcard_id": "DAA_lec_1_6",
      "tags": [
        "regression process",
        "model fitting",
        "prediction",
        "transformation",
        "polynomial transformation",
        "quadratic model",
        "curvilinear relationship"
      ]
    }
  ]
}