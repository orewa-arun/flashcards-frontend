{
  "questions": [
    {
      "type": "mcq",
      "question_text": "What is the primary purpose of performing regression diagnostics in data analysis?",
      "question_visual": null,
      "question_visual_type": "None",
      "options": {
        "A": "To increase the R-squared value of the model.",
        "B": "To ensure the model's inferences and predictions are reliable and robust.",
        "C": "To automatically correct all assumption violations without user intervention.",
        "D": "To simplify the model by removing all insignificant predictor variables."
      },
      "correct_answer": [
        "B"
      ],
      "explanation": {
        "text": "Regression diagnostics is a critical process to evaluate a model's underlying assumptions. Its primary purpose is to ensure that the conclusions drawn (inferences) and future estimates (predictions) from the model are trustworthy and consistent, preventing flawed business decisions. Option A is incorrect because increasing R-squared is not the primary goal; reliability is. Options C and D describe potential outcomes or separate steps, not the core purpose of diagnostics.",
        "step_by_step": [],
        "interpretation": "Without reliable diagnostics, a model might appear to perform well based on simple metrics like R-squared, but its predictions could be misleading in real-world scenarios.",
        "business_context": "For a business, relying on an unreliable model can lead to significant financial losses or misallocation of resources. Diagnostics act as a quality control step."
      },
      "difficulty_level": 1,
      "source_flashcard_id": "DAA_lec_3_1",
      "tags": [
        "Regression",
        "Diagnostics",
        "Model Validation",
        "Reliability"
      ],
      "visual_type": "None",
      "visual_code": "",
      "alt_text": ""
    },
    {
      "type": "mcq",
      "question_text": "Which of the following best describes the core concept of regression diagnostics?",
      "question_visual": null,
      "question_visual_type": "None",
      "options": {
        "A": "A method to select the best subset of predictor variables.",
        "B": "A systematic process of evaluating a regression model's underlying assumptions.",
        "C": "A technique to transform non-linear relationships into linear ones.",
        "D": "A way to calculate the significance of each predictor variable."
      },
      "correct_answer": [
        "B"
      ],
      "explanation": {
        "text": "Regression diagnostics is fundamentally about checking if the conditions required for a regression model to be valid are met. This involves systematically evaluating its underlying assumptions. Option A is a related but separate process (model selection). Option C is a remedial action, not the diagnostic process itself. Option D describes part of interpreting model output, not diagnostics.",
        "step_by_step": [],
        "interpretation": "Understanding the assumptions (e.g., linearity, normality, homoscedasticity) is key to understanding diagnostics.",
        "business_context": "Just as a product needs quality control checks, a statistical model needs diagnostic checks to ensure it's fit for purpose."
      },
      "difficulty_level": 1,
      "source_flashcard_id": "DAA_lec_3_1",
      "tags": [
        "Regression",
        "Diagnostics",
        "Assumptions",
        "Model Validation"
      ],
      "visual_type": "None",
      "visual_code": "",
      "alt_text": ""
    },
    {
      "type": "mcq",
      "question_text": "Ignoring regression diagnostics and only looking at R-squared and p-values can lead to what outcome?",
      "question_visual": null,
      "question_visual_type": "None",
      "options": {
        "A": "Guaranteed accurate and reliable predictions.",
        "B": "Identification of all influential observations.",
        "C": "Seemingly strong results that are actually unreliable.",
        "D": "Automatic correction of model misspecification."
      },
      "correct_answer": [
        "C"
      ],
      "explanation": {
        "text": "A common mistake is to rely solely on R-squared and p-values. While these metrics provide some information, they do not assess the underlying assumptions of the model. Ignoring diagnostics can lead to models with high R-squared values or significant p-values that are built on violated assumptions, making their results untrustworthy. Options A, B, and D are incorrect as they describe positive outcomes that would not occur from ignoring diagnostics; in fact, the opposite is likely.",
        "step_by_step": [],
        "interpretation": "R-squared and p-values summarize model fit and significance, but not its foundational integrity.",
        "business_context": "A business might invest heavily based on a model that looks good on paper (high R-squared) but fails in practice due to unaddressed diagnostic issues."
      },
      "difficulty_level": 1,
      "source_flashcard_id": "DAA_lec_3_1",
      "tags": [
        "Regression",
        "Diagnostics",
        "Common Mistakes",
        "R-squared",
        "P-values"
      ],
      "visual_type": "None",
      "visual_code": "",
      "alt_text": ""
    },
    {
      "type": "mcq",
      "question_text": "Which analogy best describes the role of regression diagnostics?",
      "question_visual": null,
      "question_visual_type": "None",
      "options": {
        "A": "A scientist designing an experiment to collect new data.",
        "B": "A pilot performing a pre-flight checklist before takeoff.",
        "C": "A chef adding spices to improve the flavor of a dish.",
        "D": "A painter choosing colors for a new canvas."
      },
      "correct_answer": [
        "B"
      ],
      "explanation": {
        "text": "The analogy of a pilot performing a pre-flight checklist is apt. Just as a pilot meticulously checks all systems to ensure a safe and reliable flight, regression diagnostics involves systematically checking a model's 'systems' (assumptions and data points) to ensure its reliability before 'taking off' with business decisions. Options A, C, and D describe creative or preparatory steps, but not the critical validation and safety check aspect.",
        "step_by_step": [],
        "interpretation": "The analogy emphasizes the systematic, critical, and preventative nature of diagnostics.",
        "business_context": "This highlights that diagnostics is a necessary step to prevent problems, much like maintenance prevents equipment failure."
      },
      "difficulty_level": 1,
      "source_flashcard_id": "DAA_lec_3_1",
      "tags": [
        "Regression",
        "Diagnostics",
        "Analogy"
      ],
      "visual_type": "None",
      "visual_code": "",
      "alt_text": ""
    },
    {
      "type": "mcq",
      "question_text": "A marketing team uses a regression model to predict sales from advertising spend. What specific risk does ignoring regression diagnostics pose before allocating a large budget?",
      "question_visual": null,
      "question_visual_type": "None",
      "options": {
        "A": "The model will automatically select too many predictor variables.",
        "B": "The advertising campaign will always fail, regardless of the model.",
        "C": "The model might provide unreliable predictions, leading to misallocation of funds.",
        "D": "The R-squared value of the model will decrease significantly."
      },
      "correct_answer": [
        "C"
      ],
      "explanation": {
        "text": "Ignoring regression diagnostics means the marketing team might be operating with a model that violates its underlying assumptions. This can lead to unreliable predictions, such as overestimating sales for high ad spends or misjudging the campaign's effectiveness. Consequently, this could result in a significant misallocation of the advertising budget based on faulty forecasts. Option A is incorrect as diagnostics don't directly control variable selection in this context. Option B is an extreme and unlikely outcome. Option D is incorrect; R-squared might remain high even if the model is unreliable.",
        "step_by_step": [],
        "interpretation": "The 'real-world use case' highlights the practical consequences of diagnostic failures.",
        "business_context": "In a business setting, unreliable predictions translate directly to poor decision-making and wasted resources."
      },
      "difficulty_level": 1,
      "source_flashcard_id": "DAA_lec_3_1",
      "tags": [
        "Regression",
        "Diagnostics",
        "Business Decision Making",
        "Real-world use case"
      ],
      "visual_type": "None",
      "visual_code": "",
      "alt_text": ""
    },
    {
      "type": "mcq",
      "question_text": "In regression analysis, what does a residual represent?",
      "question_visual": {
        "type": "latex",
        "expression": "e_i = Y_i - \\hat{Y}_i",
        "description": "Formula for a residual"
      },
      "question_visual_type": "latex",
      "options": {
        "A": "The predicted value of the response variable.",
        "B": "The difference between the observed and predicted values of the response variable.",
        "C": "The value of the predictor variable.",
        "D": "The coefficient of the regression model."
      },
      "correct_answer": [
        "B"
      ],
      "explanation": {
        "text": "A residual (e_i) is defined as the difference between the actual observed value (Y_i) and the value predicted by the regression model (Ŷ_i). It quantifies how much the model 'missed' the actual data point. Options A, C, and D describe other components of a regression model, not the residual itself.",
        "step_by_step": [
          {
            "step": 1,
            "title": "Define Observed Value",
            "content": "The observed value, Y_i, is the actual data point recorded for the response variable.",
            "latex": "Y_i"
          },
          {
            "step": 2,
            "title": "Define Predicted Value",
            "content": "The predicted value, Ŷ_i, is the value that the regression model estimates for the response variable given the predictor values.",
            "latex": "\\hat{Y}_i"
          },
          {
            "step": 3,
            "title": "Calculate Residual",
            "content": "The residual, e_i, is simply the difference between the observed and predicted values.",
            "latex": "e_i = Y_i - \\hat{Y}_i"
          }
        ],
        "interpretation": "A residual indicates the error of the model's prediction for a specific observation.",
        "business_context": "In a business context, a residual could represent the difference between actual sales and predicted sales for a given marketing campaign."
      },
      "difficulty_level": 1,
      "source_flashcard_id": "DAA_lec_3_2",
      "tags": [
        "Residuals",
        "Regression",
        "Definition"
      ],
      "visual_type": "None",
      "visual_code": "",
      "alt_text": ""
    },
    {
      "type": "mcq",
      "question_text": "When creating a residual plot (residuals vs. fitted values), what is typically plotted on the vertical (y) axis?",
      "question_visual": {
        "type": "matplotlib",
        "plot_type": "scatter",
        "params": {
          "x_data": [
            10,
            20,
            30,
            40,
            50
          ],
          "y_data": [
            -2,
            1,
            0,
            -1,
            2
          ],
          "xlabel": "Fitted Values",
          "ylabel": "Residuals",
          "title": "Example Residual Plot",
          "line_at_zero": true
        }
      },
      "question_visual_type": "matplotlib",
      "options": {
        "A": "The observed values of the response variable.",
        "B": "The predicted values of the response variable.",
        "C": "The residuals (errors) of the model.",
        "D": "The predictor variable values."
      },
      "correct_answer": [
        "C"
      ],
      "explanation": {
        "text": "A residual plot is specifically designed to visualize the errors of the model. Therefore, the residuals (the differences between observed and predicted values) are always plotted on the vertical (y) axis. The horizontal (x) axis typically shows either the fitted (predicted) values or one of the predictor variables. Options A, B, and D are incorrect as they would be placed on the horizontal axis or are not typically plotted on the y-axis of a standard residual plot.",
        "step_by_step": [],
        "interpretation": "The y-axis representing residuals allows us to see how errors are distributed and if they show any patterns.",
        "business_context": "Visualizing residuals helps identify if a model's prediction errors are systematic or random, which is crucial for trusting the model."
      },
      "difficulty_level": 1,
      "source_flashcard_id": "DAA_lec_3_2",
      "tags": [
        "Residual Plots",
        "Residuals",
        "Graphical Tools"
      ],
      "visual_type": "None",
      "visual_code": "",
      "alt_text": ""
    },
    {
      "type": "mcq",
      "question_text": "A 'fanning-out' pattern in a residual plot (where residuals spread wider as fitted values increase) indicates which assumption violation?",
      "question_visual": {
        "type": "matplotlib",
        "plot_type": "scatter",
        "params": {
          "x_data": [
            1,
            2,
            3,
            4,
            5,
            6,
            7,
            8,
            9,
            10
          ],
          "y_data": [
            -0.5,
            0.2,
            -0.8,
            1.0,
            -1.5,
            2.0,
            -2.5,
            3.0,
            -3.5,
            4.0
          ],
          "x_error": [
            0.2,
            0.3,
            0.4,
            0.5,
            0.6,
            0.7,
            0.8,
            0.9,
            1.0,
            1.1
          ],
          "y_error": [
            0.5,
            0.6,
            0.7,
            0.8,
            0.9,
            1.0,
            1.1,
            1.2,
            1.3,
            1.4
          ],
          "xlabel": "Fitted Values",
          "ylabel": "Residuals",
          "title": "Fanning-Out Residual Plot (Heteroscedasticity)",
          "line_at_zero": true,
          "y_min": -5,
          "y_max": 5
        }
      },
      "question_visual_type": "matplotlib",
      "options": {
        "A": "Non-linearity.",
        "B": "Non-normality of errors.",
        "C": "Multicollinearity.",
        "D": "Heteroscedasticity."
      },
      "correct_answer": [
        "D"
      ],
      "explanation": {
        "text": "A 'fanning-out' or 'funnel' shape in a residual plot, where the spread of residuals increases (or decreases) with the fitted values, is a clear indicator of heteroscedasticity. This means the variance of the errors is not constant across all levels of the predictor or fitted values, violating a key assumption of OLS regression. Option A (non-linearity) typically shows a curved pattern. Option B (non-normality) is checked with a Q-Q plot. Option C (multicollinearity) is a problem with predictor variables, not directly seen in a residual plot this way.",
        "step_by_step": [],
        "interpretation": "Heteroscedasticity makes standard errors and p-values unreliable, affecting confidence intervals and hypothesis tests.",
        "business_context": "If a model predicting sales shows heteroscedasticity, it means the certainty of its predictions varies. Predictions for low sales might be accurate, but for high sales, they could be very uncertain."
      },
      "difficulty_level": 1,
      "source_flashcard_id": "DAA_lec_3_2",
      "tags": [
        "Residual Plots",
        "Heteroscedasticity",
        "Assumption Violations"
      ],
      "visual_type": "None",
      "visual_code": "",
      "alt_text": ""
    },
    {
      "type": "mcq",
      "question_text": "If a residual plot shows a distinct 'U-shaped' or 'inverted U-shaped' pattern, what does this primarily suggest about the regression model?",
      "question_visual": {
        "type": "matplotlib",
        "plot_type": "scatter",
        "params": {
          "x_data": [
            1,
            2,
            3,
            4,
            5,
            6,
            7,
            8,
            9,
            10
          ],
          "y_data": [
            2.5,
            1.0,
            0.0,
            -0.5,
            -0.8,
            -0.5,
            0.0,
            1.0,
            2.5,
            4.0
          ],
          "xlabel": "Fitted Values",
          "ylabel": "Residuals",
          "title": "U-Shaped Residual Plot (Non-linearity)",
          "line_at_zero": true,
          "y_min": -1,
          "y_max": 5
        }
      },
      "question_visual_type": "matplotlib",
      "options": {
        "A": "The errors are normally distributed.",
        "B": "The model has no influential observations.",
        "C": "The linear relationship assumption is violated (non-linearity).",
        "D": "There is a problem with multicollinearity."
      },
      "correct_answer": [
        "C"
      ],
      "explanation": {
        "text": "A 'U-shaped' or 'inverted U-shaped' pattern in a residual plot strongly suggests that the linear regression model is missing a non-linear component. This indicates that the assumed linear relationship between the predictor(s) and the response variable is incorrect, violating the linearity assumption. Option A refers to normality, typically checked by a Q-Q plot. Option B relates to influential observations, measured by other diagnostics. Option D is about predictor correlation, not usually seen as this pattern in residuals.",
        "step_by_step": [],
        "interpretation": "This pattern means the model systematically over- or under-predicts at certain ranges, failing to capture the true underlying relationship.",
        "business_context": "If predicting customer satisfaction and a U-shape appears, it means a simple linear model isn't capturing how satisfaction changes across, for example, product usage levels. A more complex (e.g., quadratic) model might be needed."
      },
      "difficulty_level": 1,
      "source_flashcard_id": "DAA_lec_3_2",
      "tags": [
        "Residual Plots",
        "Non-linearity",
        "Assumption Violations"
      ],
      "visual_type": "None",
      "visual_code": "",
      "alt_text": ""
    },
    {
      "type": "mca",
      "question_text": "Which of the following assumption violations can typically be identified by examining residual plots? (Select all that apply)",
      "question_visual": null,
      "question_visual_type": "None",
      "options": {
        "A": "Non-linearity of the relationship.",
        "B": "Heteroscedasticity (non-constant variance of errors).",
        "C": "Normality of errors.",
        "D": "Independence of errors."
      },
      "correct_answer": [
        "A",
        "B"
      ],
      "explanation": {
        "text": "Residual plots are excellent visual tools for identifying specific patterns that indicate assumption violations. A 'U-shaped' or curved pattern suggests non-linearity (A). A 'fanning-out' or 'funnel' shape indicates heteroscedasticity (B). While a Normal Q-Q plot (a type of residual plot) can assess normality (C), a standard residual vs. fitted plot primarily reveals non-linearity and heteroscedasticity. Independence of errors (D) is often checked by plotting residuals against time or order of observation, which is a specific type of residual plot, but A and B are the most common direct detections from a general residual vs. fitted plot.",
        "step_by_step": [],
        "interpretation": "Understanding what each pattern signifies is crucial for effective diagnostic analysis.",
        "business_context": "Identifying these issues early helps refine models to give more trustworthy insights into business phenomena."
      },
      "difficulty_level": 1,
      "source_flashcard_id": "DAA_lec_3_2",
      "tags": [
        "Residual Plots",
        "Non-linearity",
        "Heteroscedasticity",
        "Assumption Violations",
        "MCA"
      ],
      "visual_type": "None",
      "visual_code": "",
      "alt_text": ""
    },
    {
      "type": "mcq",
      "question_text": "What characterizes an 'outlier' in a regression model?",
      "question_visual": {
        "type": "matplotlib",
        "plot_type": "scatter",
        "params": {
          "x_data": [
            1,
            2,
            3,
            4,
            5,
            6,
            7,
            8,
            9,
            10
          ],
          "y_data": [
            2,
            4,
            5,
            7,
            9,
            11,
            13,
            15,
            17,
            0
          ],
          "xlabel": "Predictor (X)",
          "ylabel": "Response (Y)",
          "title": "Scatter Plot with an Outlier",
          "annotate_points": [
            {
              "x": 10,
              "y": 0,
              "text": "Outlier"
            }
          ],
          "regression_line": true
        }
      },
      "question_visual_type": "matplotlib",
      "options": {
        "A": "An observation with extreme predictor variable values.",
        "B": "An observation that, if removed, drastically changes coefficients.",
        "C": "An observation with an unusually large residual.",
        "D": "An observation with a predicted value far from the mean."
      },
      "correct_answer": [
        "C"
      ],
      "explanation": {
        "text": "An outlier is defined as an observation that has an unusually large residual, meaning its observed Y-value is far from its predicted Y-value, given the model. Option A describes a leverage point. Option B describes an influential observation. Option D is incorrect; a predicted value far from the mean is not directly the definition of an outlier.",
        "step_by_step": [],
        "interpretation": "Outliers are data points where the model's prediction is significantly wrong.",
        "business_context": "In sales prediction, an outlier might be a particular product that sold far less or far more than expected based on its features and marketing spend."
      },
      "difficulty_level": 1,
      "source_flashcard_id": "DAA_lec_3_3",
      "tags": [
        "Outliers",
        "Regression Diagnostics",
        "Definition"
      ],
      "visual_type": "None",
      "visual_code": "",
      "alt_text": ""
    },
    {
      "type": "mcq",
      "question_text": "What defines a 'leverage' point in regression analysis?",
      "question_visual": {
        "type": "matplotlib",
        "plot_type": "scatter",
        "params": {
          "x_data": [
            1,
            2,
            3,
            4,
            5,
            6,
            7,
            8,
            9,
            10
          ],
          "y_data": [
            2,
            4,
            5,
            7,
            9,
            11,
            13,
            15,
            17,
            20
          ],
          "xlabel": "Predictor (X)",
          "ylabel": "Response (Y)",
          "title": "Scatter Plot with High Leverage Point",
          "annotate_points": [
            {
              "x": 10,
              "y": 20,
              "text": "Leverage Point"
            }
          ],
          "regression_line": true,
          "x_range": [
            0,
            11
          ],
          "y_range": [
            0,
            22
          ]
        }
      },
      "question_visual_type": "matplotlib",
      "options": {
        "A": "An observation with an unusually large residual.",
        "B": "An observation that, if removed, drastically changes coefficients.",
        "C": "An observation with extreme predictor variable values (X is far from mean X).",
        "D": "An observation whose Y-value is far from the mean Y."
      },
      "correct_answer": [
        "C"
      ],
      "explanation": {
        "text": "A leverage point is an observation that has extreme values for its predictor variable(s), placing it far from the center of the X-data. These points have the potential to exert a strong pull on the regression line. Option A describes an outlier. Option B describes an influential observation. Option D is incorrect; a Y-value far from the mean is simply a high or low response, not necessarily indicating leverage.",
        "step_by_step": [],
        "interpretation": "Leverage points are 'extreme' in the input space, giving them more 'power' to shape the regression line.",
        "business_context": "In a model predicting house prices, a mansion with 10,000 sq ft in a neighborhood of 2,000 sq ft homes would be a high leverage point due to its extreme size (X value)."
      },
      "difficulty_level": 1,
      "source_flashcard_id": "DAA_lec_3_3",
      "tags": [
        "Leverage",
        "Regression Diagnostics",
        "Definition"
      ],
      "visual_type": "None",
      "visual_code": "",
      "alt_text": ""
    },
    {
      "type": "mcq",
      "question_text": "An observation is considered 'influential' in regression if its removal from the dataset would lead to what?",
      "question_visual": {
        "type": "matplotlib",
        "plot_type": "scatter",
        "params": {
          "x_data": [
            1,
            2,
            3,
            4,
            5,
            6,
            7,
            8,
            9,
            10
          ],
          "y_data": [
            2,
            4,
            5,
            7,
            9,
            11,
            13,
            15,
            17,
            2
          ],
          "xlabel": "Predictor (X)",
          "ylabel": "Response (Y)",
          "title": "Scatter Plot with Influential Point",
          "annotate_points": [
            {
              "x": 10,
              "y": 2,
              "text": "Influential Point"
            }
          ],
          "regression_line": true,
          "regression_line_params": {
            "color": "blue",
            "linestyle": "-"
          },
          "show_alternative_line": true,
          "alternative_line_x_data": [
            1,
            2,
            3,
            4,
            5,
            6,
            7,
            8,
            9
          ],
          "alternative_line_y_data": [
            2,
            4,
            5,
            7,
            9,
            11,
            13,
            15,
            17
          ],
          "alternative_line_params": {
            "color": "red",
            "linestyle": "--"
          }
        }
      },
      "question_visual_type": "matplotlib",
      "options": {
        "A": "No change in the model's R-squared value.",
        "B": "A drastic change in the estimated regression coefficients.",
        "C": "The residuals of all other observations becoming zero.",
        "D": "The model's ability to predict future values becoming perfect."
      },
      "correct_answer": [
        "B"
      ],
      "explanation": {
        "text": "An influential observation is one that, due to its unique combination of extreme predictor values (leverage) and/or an unusually large residual (outlier), has a disproportionate impact on the regression model. If such an observation is removed, the estimated regression coefficients would drastically change. Options A, C, and D describe unlikely or incorrect consequences of removing an influential point.",
        "step_by_step": [],
        "interpretation": "Influential points are problematic because they can distort the true relationship between variables.",
        "business_context": "If a single customer's data point dramatically alters how a company understands its customer base, that customer is influential and needs careful review."
      },
      "difficulty_level": 1,
      "source_flashcard_id": "DAA_lec_3_3",
      "tags": [
        "Influence",
        "Regression Diagnostics",
        "Definition"
      ],
      "visual_type": "None",
      "visual_code": "",
      "alt_text": ""
    },
    {
      "type": "mcq",
      "question_text": "Which diagnostic measure is commonly used to quantify an observation's overall influence on a regression model's coefficients?",
      "question_visual": null,
      "question_visual_type": "None",
      "options": {
        "A": "R-squared.",
        "B": "P-value.",
        "C": "Cook's Distance.",
        "D": "Standard Error."
      },
      "correct_answer": [
        "C"
      ],
      "explanation": {
        "text": "Cook's Distance is a widely used diagnostic statistic that measures how much the regression coefficients change if a particular observation is removed from the dataset. A high Cook's Distance indicates an influential observation. Options A (R-squared) measures overall model fit. Option B (P-value) assesses the statistical significance of coefficients. Option D (Standard Error) measures the precision of coefficient estimates. None of these directly quantify influence in the same way as Cook's Distance.",
        "step_by_step": [],
        "interpretation": "Cook's Distance combines aspects of both leverage and outlier status into a single measure of influence.",
        "business_context": "Identifying influential data points using Cook's Distance helps analysts decide whether to investigate, transform, or potentially remove such data to build a more robust model."
      },
      "difficulty_level": 1,
      "source_flashcard_id": "DAA_lec_3_3",
      "tags": [
        "Influence",
        "Cook's Distance",
        "Regression Diagnostics",
        "Measures"
      ],
      "visual_type": "None",
      "visual_code": "",
      "alt_text": ""
    },
    {
      "type": "mcq",
      "question_text": "A data point in a regression model has an extreme X-value (high leverage) but its Y-value falls perfectly on the regression line (small residual). Is this point necessarily influential?",
      "question_visual": null,
      "question_visual_type": "None",
      "options": {
        "A": "Yes, because all high leverage points are influential.",
        "B": "Yes, because it has an extreme X-value.",
        "C": "No, because influence requires both high leverage AND a large residual.",
        "D": "No, because only outliers can be influential."
      },
      "correct_answer": [
        "C"
      ],
      "explanation": {
        "text": "An observation needs both high leverage (extreme X-values) and a large residual (Y-value far from the predicted Y) to be highly influential. If a high leverage point's Y-value aligns well with the regression line (small residual), it does not drastically pull the line towards itself, and thus, it may not be influential. Options A and B are common misconceptions. Option D is incorrect because an outlier with average X-values can also be influential if its residual is extremely large.",
        "step_by_step": [],
        "interpretation": "Influence is a combined effect. Leverage provides the 'potential' for influence, but the 'realization' of influence depends on the residual.",
        "business_context": "Distinguishing between leverage and influence is crucial for not overreacting to data points that simply represent extreme but valid observations."
      },
      "difficulty_level": 1,
      "source_flashcard_id": "DAA_lec_3_3",
      "tags": [
        "Leverage",
        "Influence",
        "Common Mistakes",
        "Regression Diagnostics"
      ],
      "visual_type": "None",
      "visual_code": "",
      "alt_text": ""
    },
    {
      "type": "mcq",
      "question_text": "What is the primary purpose of ensuring the core assumptions of Ordinary Least Squares (OLS) regression are met?",
      "question_visual": null,
      "question_visual_type": "None",
      "options": {
        "A": "To guarantee that the model always achieves a perfect R-squared value.",
        "B": "To ensure the OLS coefficient estimates are always exactly zero.",
        "C": "To validate the statistical inferences (e.g., p-values, confidence intervals) drawn from the model.",
        "D": "To increase the computational speed of the regression algorithm."
      },
      "correct_answer": [
        "C"
      ],
      "explanation": {
        "text": "The core OLS assumptions, such as linearity, independence, normality of errors, and homoscedasticity, are crucial for the validity of statistical inferences. If these assumptions are violated, while the coefficient estimates might still be unbiased, the standard errors, p-values, and confidence intervals derived from the model become unreliable, leading to potentially incorrect conclusions about predictor significance. Option A and B are incorrect as the assumptions do not guarantee a perfect R-squared or zero coefficients. Option D is unrelated to the purpose of assumptions.",
        "step_by_step": [],
        "interpretation": "Meeting OLS assumptions allows us to trust the statistical tests and predictions made by our model, which is essential for sound decision-making.",
        "business_context": "In business, reliable statistical inferences are vital for making informed decisions, such as which marketing campaigns are truly effective or which financial factors significantly influence stock prices. Without valid inferences, strategic choices could be based on misleading data."
      },
      "difficulty_level": 1,
      "source_flashcard_id": "DAA_lec_3_4",
      "tags": [
        "OLS",
        "Assumptions",
        "Inference",
        "Validity"
      ],
      "visual_type": "None",
      "visual_code": "",
      "alt_text": ""
    },
    {
      "type": "mcq",
      "question_text": "Which OLS assumption states that the error term (residuals) should be normally distributed?",
      "question_visual": {
        "type": "matplotlib",
        "plot_type": "normal_distribution",
        "params": {
          "mean": 0,
          "std": 1,
          "title": "Example of a Normal Distribution"
        }
      },
      "question_visual_type": "matplotlib",
      "options": {
        "A": "Linearity",
        "B": "Independence",
        "C": "Normality",
        "D": "Homoscedasticity"
      },
      "correct_answer": [
        "C"
      ],
      "explanation": {
        "text": "The Normality assumption explicitly states that the errors of the regression model should follow a normal distribution. This is particularly important for the validity of t-tests and F-tests, especially in smaller samples. The provided diagram illustrates a typical normal distribution curve, which the errors should resemble. Option A refers to the relationship between variables, B to error correlation, and D to error variance.",
        "step_by_step": [],
        "interpretation": "A normal distribution of errors implies that prediction errors are symmetric around zero, with most errors being small and fewer errors being very large.",
        "business_context": "If errors are not normally distributed, confidence intervals and p-values for coefficients may be inaccurate, leading to misjudgments about the reliability of a model's predictions, for example, when forecasting sales or customer churn."
      },
      "difficulty_level": 1,
      "source_flashcard_id": "DAA_lec_3_4",
      "tags": [
        "OLS",
        "Assumptions",
        "Normality",
        "Errors"
      ],
      "visual_type": "None",
      "visual_code": "",
      "alt_text": ""
    },
    {
      "type": "mcq",
      "question_text": "If the errors in an OLS regression model are correlated with each other (i.e., not independent), which assumption is violated?",
      "question_visual": null,
      "question_visual_type": "None",
      "options": {
        "A": "Homoscedasticity",
        "B": "Linearity",
        "C": "Normality",
        "D": "Independence"
      },
      "correct_answer": [
        "D"
      ],
      "explanation": {
        "text": "The Independence assumption requires that the errors (residuals) of the model are uncorrelated with each other. Violations, often seen in time series data, can lead to underestimated standard errors and unreliable hypothesis tests. Option A refers to constant variance, B to the functional form, and C to the distribution of errors.",
        "step_by_step": [],
        "interpretation": "Independent errors mean that the error for one observation does not provide information about the error for another observation. This ensures each piece of data contributes uniquely to the error estimation.",
        "business_context": "In financial time series analysis, if errors in predicting stock prices are correlated day-to-day, then the model's assessment of risk and the significance of predictors will be flawed, potentially leading to poor investment decisions."
      },
      "difficulty_level": 1,
      "source_flashcard_id": "DAA_lec_3_4",
      "tags": [
        "OLS",
        "Assumptions",
        "Independence",
        "Errors"
      ],
      "visual_type": "None",
      "visual_code": "",
      "alt_text": ""
    },
    {
      "type": "mcq",
      "question_text": "Which of the following is NOT a core assumption of Ordinary Least Squares (OLS) regression for valid inferences?",
      "question_visual": null,
      "question_visual_type": "None",
      "options": {
        "A": "Linearity of the relationship between variables.",
        "B": "Independence of errors.",
        "C": "Perfect multicollinearity among predictors.",
        "D": "Homoscedasticity of errors."
      },
      "correct_answer": [
        "C"
      ],
      "explanation": {
        "text": "Perfect multicollinearity (where one predictor is a perfect linear combination of others) is a problem for OLS, but the assumption is actually 'No Multicollinearity' (or at least, no *perfect* multicollinearity), meaning predictors should not be highly correlated with each other. The presence of perfect multicollinearity would prevent the model from even being estimated. Linearity, Independence, and Homoscedasticity are all core assumptions. Therefore, 'Perfect multicollinearity among predictors' is the opposite of an assumption, making it the correct answer to which is NOT an assumption.",
        "step_by_step": [],
        "interpretation": "The absence of multicollinearity is desired, so perfect multicollinearity is a violation or a situation that prevents OLS from working, not an assumption for valid inferences.",
        "business_context": "If a marketing model included 'total ad spend' and 'sum of digital ad spend and TV ad spend' as separate predictors, this perfect multicollinearity would make it impossible to determine the individual effect of each component, leading to an unestimable model."
      },
      "difficulty_level": 1,
      "source_flashcard_id": "DAA_lec_3_4",
      "tags": [
        "OLS",
        "Assumptions",
        "Multicollinearity",
        "Anti-Concept"
      ],
      "visual_type": "None",
      "visual_code": "",
      "alt_text": ""
    },
    {
      "type": "mcq",
      "question_text": "When the variance of the error term in an OLS regression model is constant across all levels of the independent variables, this condition is known as:",
      "question_visual": null,
      "question_visual_type": "None",
      "options": {
        "A": "Heteroscedasticity",
        "B": "Autocorrelation",
        "C": "Homoscedasticity",
        "D": "Normality"
      },
      "correct_answer": [
        "C"
      ],
      "explanation": {
        "text": "Homoscedasticity is the assumption that the variance of the error term (residuals) is constant across all levels of the independent variables. This means the spread of the residuals should be roughly the same throughout the range of the predictor variables. Option A (Heteroscedasticity) is the violation of this assumption, B (Autocorrelation) relates to independence, and D (Normality) refers to the distribution of errors.",
        "step_by_step": [],
        "interpretation": "Constant error variance implies that the model's predictive accuracy is consistent across the entire range of the independent variables.",
        "business_context": "In a model predicting customer spending, homoscedasticity would mean the model's prediction errors are equally spread out for both low-spending and high-spending customers, giving equal confidence in predictions across the board."
      },
      "difficulty_level": 1,
      "source_flashcard_id": "DAA_lec_3_4",
      "tags": [
        "OLS",
        "Assumptions",
        "Homoscedasticity",
        "Variance"
      ],
      "visual_type": "None",
      "visual_code": "",
      "alt_text": ""
    },
    {
      "type": "mcq",
      "question_text": "What is Homoscedasticity in the context of OLS regression assumptions?",
      "question_visual": null,
      "question_visual_type": "None",
      "options": {
        "A": "The errors are normally distributed.",
        "B": "The variance of the error term is constant across all levels of the independent variables.",
        "C": "The independent variables are linearly related to the dependent variable.",
        "D": "There is no correlation between the error terms."
      },
      "correct_answer": [
        "B"
      ],
      "explanation": {
        "text": "Homoscedasticity is the assumption that the variance of the error term (ε) remains constant across all values of the independent variables. This means the spread of the residuals should not change systematically with the predicted values or independent variables. Option A describes normality, C describes linearity, and D describes independence of errors.",
        "step_by_step": [],
        "interpretation": "When errors have constant variance, the precision of our model's predictions is consistent across the entire range of observations.",
        "business_context": "For a bank predicting loan defaults, homoscedasticity would mean the model's prediction accuracy is consistent for both low-risk and high-risk applicants, preventing misleading assessments of risk for specific customer segments."
      },
      "difficulty_level": 1,
      "source_flashcard_id": "DAA_lec_3_5",
      "tags": [
        "Homoscedasticity",
        "OLS Assumptions",
        "Error Variance"
      ],
      "visual_type": "None",
      "visual_code": "",
      "alt_text": ""
    },
    {
      "type": "mcq",
      "question_text": "What is the primary consequence of violating the homoscedasticity assumption (i.e., experiencing heteroscedasticity) in OLS regression?",
      "question_visual": null,
      "question_visual_type": "None",
      "options": {
        "A": "The OLS coefficient estimates become biased.",
        "B": "The OLS coefficient estimates become inconsistent.",
        "C": "The standard errors of the coefficients become incorrect, invalidating inferential statistics.",
        "D": "The model's R-squared value will always decrease."
      },
      "correct_answer": [
        "C"
      ],
      "explanation": {
        "text": "When heteroscedasticity is present, OLS coefficient estimates remain unbiased and consistent, but they are no longer the most efficient. Crucially, their standard errors become incorrect. This invalidates inferential statistics such as t-tests, F-tests, and confidence intervals, making it impossible to trust the significance of predictors. Options A and B are common misconceptions; the coefficients themselves are still unbiased. Option D is not a guaranteed consequence.",
        "step_by_step": [],
        "interpretation": "Incorrect standard errors mean that our assessment of the precision and significance of our predictor variables is unreliable.",
        "business_context": "If a marketing analyst ignores heteroscedasticity, they might conclude that an advertising channel is statistically significant (based on an incorrect p-value) when it is not, leading to misallocation of marketing budget."
      },
      "difficulty_level": 1,
      "source_flashcard_id": "DAA_lec_3_5",
      "tags": [
        "Heteroscedasticity",
        "OLS Assumptions",
        "Standard Errors",
        "Inference"
      ],
      "visual_type": "None",
      "visual_code": "",
      "alt_text": ""
    },
    {
      "type": "mcq",
      "question_text": "Which of the following statements is true regarding the impact of heteroscedasticity on OLS coefficient estimates?",
      "question_visual": null,
      "question_visual_type": "None",
      "options": {
        "A": "OLS coefficient estimates become biased.",
        "B": "OLS coefficient estimates become inconsistent.",
        "C": "OLS coefficient estimates remain unbiased and consistent.",
        "D": "OLS coefficient estimates are automatically set to zero."
      },
      "correct_answer": [
        "C"
      ],
      "explanation": {
        "text": "A common misconception is that heteroscedasticity biases OLS coefficient estimates. In reality, OLS coefficient estimates remain unbiased and consistent even in the presence of heteroscedasticity. However, they are no longer the most efficient, and more importantly, their standard errors become incorrect, invalidating inferential statistics.",
        "step_by_step": [],
        "interpretation": "This means that while the model might still, on average, give correct estimates for the relationships between variables, we cannot trust the statistical 'certainty' or 'significance' of those relationships.",
        "business_context": "An economist modeling economic growth might still get accurate average impacts of policy changes despite heteroscedasticity, but they can't confidently state if an impact is 'statistically significant' or rely on the precision of their estimates for policy recommendations."
      },
      "difficulty_level": 1,
      "source_flashcard_id": "DAA_lec_3_5",
      "tags": [
        "Heteroscedasticity",
        "OLS Assumptions",
        "Coefficient Estimates",
        "Bias"
      ],
      "visual_type": "None",
      "visual_code": "",
      "alt_text": ""
    },
    {
      "type": "mcq",
      "question_text": "Which type of plot is most commonly used to visually detect heteroscedasticity in OLS regression?",
      "question_visual": {
        "type": "matplotlib",
        "plot_type": "scatter",
        "params": {
          "x": [
            1,
            2,
            3,
            4,
            5,
            6,
            7,
            8,
            9,
            10
          ],
          "y": [
            0.5,
            -0.2,
            0.8,
            -0.6,
            1.5,
            -1.8,
            2.5,
            -2.9,
            3.5,
            -3.8
          ],
          "xlabel": "Predicted Values (Ŷ)",
          "ylabel": "Residuals (e)",
          "title": "Example Residual Plot Showing Fanning Out"
        }
      },
      "question_visual_type": "matplotlib",
      "options": {
        "A": "Histogram of the dependent variable",
        "B": "Scatter plot of residuals versus predicted values (or an independent variable)",
        "C": "Box plot of independent variables",
        "D": "Time series plot of the dependent variable"
      },
      "correct_answer": [
        "B"
      ],
      "explanation": {
        "text": "A scatter plot of residuals against predicted values (or against one of the independent variables) is the most effective visual tool for detecting heteroscedasticity. A 'fanning-out' or 'funnel' shape in such a plot indicates that the variance of the residuals is not constant, as shown in the accompanying diagram where residuals spread wider as predicted values increase. Options A, C, and D are generally not used for this specific diagnostic.",
        "step_by_step": [],
        "interpretation": "By plotting residuals against predicted values, we can visually inspect whether the spread of errors changes across the range of our model's predictions.",
        "business_context": "A financial analyst using a model to predict asset returns would examine a residual plot to ensure that the model isn't making consistently larger errors for higher predicted returns, which would distort risk assessments."
      },
      "difficulty_level": 1,
      "source_flashcard_id": "DAA_lec_3_5",
      "tags": [
        "Heteroscedasticity",
        "Residual Plots",
        "Regression Diagnostics",
        "Visualisation"
      ],
      "visual_type": "None",
      "visual_code": "",
      "alt_text": ""
    },
    {
      "type": "mca",
      "question_text": "Which of the following statements accurately describe the characteristics and consequences of **Heteroscedasticity** in OLS regression? (Select all that apply)",
      "question_visual": null,
      "question_visual_type": "None",
      "options": {
        "A": "It means the variance of the error term is not constant across all levels of the independent variables.",
        "B": "It causes OLS coefficient estimates to become biased.",
        "C": "It leads to incorrect standard errors for the OLS coefficients.",
        "D": "It invalidates inferential statistics such as t-tests and confidence intervals."
      },
      "correct_answer": [
        "A",
        "C",
        "D"
      ],
      "explanation": {
        "text": "Heteroscedasticity is indeed the condition where the error variance is not constant (A). This violation does not bias OLS coefficient estimates (so B is incorrect); they remain unbiased and consistent. However, it critically leads to incorrect standard errors (C), which in turn invalidates inferential statistics like t-tests, F-tests, and confidence intervals (D), making conclusions about predictor significance unreliable.",
        "step_by_step": [
          {
            "step": 1,
            "title": "Define Heteroscedasticity",
            "content": "Heteroscedasticity occurs when the spread of the residuals (the differences between observed and predicted values) changes across the range of the independent variables. This means the variance of the error term is not constant, violating the homoscedasticity assumption. Therefore, option A is correct."
          },
          {
            "step": 2,
            "title": "Impact on Coefficient Bias",
            "content": "A common misunderstanding is that heteroscedasticity biases OLS coefficient estimates. However, OLS estimates (β̂) remain unbiased and consistent even with heteroscedasticity. They are simply no longer the 'best linear unbiased estimators' (BLUE). Thus, option B is incorrect."
          },
          {
            "step": 3,
            "title": "Impact on Standard Errors",
            "content": "The primary practical consequence of heteroscedasticity is that the standard errors of the OLS coefficients are incorrectly estimated. They are usually underestimated, making coefficients appear more precise and statistically significant than they actually are. Therefore, option C is correct."
          },
          {
            "step": 4,
            "title": "Impact on Inferential Statistics",
            "content": "Because standard errors are incorrect, any inferential statistics that rely on them – such as t-tests (for individual coefficient significance), F-tests (for overall model significance), and confidence intervals – become invalid. This means we cannot trust the p-values or the range of possible values for our coefficients. Therefore, option D is correct."
          }
        ],
        "interpretation": "Heteroscedasticity doesn't invalidate the average relationship found by the model, but it fundamentally undermines our ability to assess the reliability and significance of those relationships.",
        "business_context": "In predicting customer lifetime value, if the model exhibits heteroscedasticity, a company might falsely believe certain marketing channels are significant drivers of high-value customers, leading to inefficient resource allocation because the confidence intervals and p-values for those channels are inaccurate."
      },
      "difficulty_level": 1,
      "source_flashcard_id": "DAA_lec_3_5",
      "tags": [
        "Heteroscedasticity",
        "OLS Assumptions",
        "Standard Errors",
        "Inferential Statistics",
        "MCA"
      ],
      "visual_type": "None",
      "visual_code": "",
      "alt_text": ""
    },
    {
      "type": "mcq",
      "question_text": "In regression analysis, what is a **vertical outlier**?",
      "question_visual": null,
      "question_visual_type": "None",
      "options": {
        "A": "An observation with an unusually large independent variable (X) value.",
        "B": "An observation with an unusually large residual (difference between observed and predicted Y).",
        "C": "An observation that significantly influences the slope of the regression line.",
        "D": "An observation that is perfectly predicted by the regression model."
      },
      "correct_answer": [
        "B"
      ],
      "explanation": {
        "text": "A vertical outlier in regression analysis is an observation where the observed response value (Yᵢ) is unusually far from the value predicted by the model (Ŷᵢ), resulting in a very large residual (eᵢ = Yᵢ - Ŷᵢ). This indicates an unusual outcome for a given set of predictor values. Option A describes leverage, C describes influential points (which might be outliers but not exclusively vertical), and D describes a perfect fit, not an outlier.",
        "step_by_step": [],
        "interpretation": "A large residual signals that for this particular data point, our model's prediction was significantly off, highlighting an exceptional case.",
        "business_context": "If a retail company's sales prediction model for a store has a vertical outlier, it means the actual sales were significantly higher or lower than predicted. Investigating this outlier might reveal unique local events (e.g., a sudden local festival, a store-specific promotion) that influenced sales, providing valuable insights beyond the standard model predictors."
      },
      "difficulty_level": 1,
      "source_flashcard_id": "DAA_lec_3_6",
      "tags": [
        "Outliers",
        "Vertical Outlier",
        "Residuals",
        "Regression Analysis"
      ],
      "visual_type": "None",
      "visual_code": "",
      "alt_text": ""
    },
    {
      "type": "mcq",
      "question_text": "How is a **residual** (eᵢ) calculated for a single observation in a regression model?",
      "question_visual": {
        "type": "latex",
        "content": "e_i = Y_i - \\hat{Y}_i",
        "label": "Residual Calculation"
      },
      "question_visual_type": "latex",
      "options": {
        "A": "Observed Response (Yᵢ) + Predicted Response (Ŷᵢ)",
        "B": "Observed Response (Yᵢ) - Predicted Response (Ŷᵢ)",
        "C": "Predicted Response (Ŷᵢ) / Observed Response (Yᵢ)",
        "D": "Independent Variable (Xᵢ) - Dependent Variable (Yᵢ)"
      },
      "correct_answer": [
        "B"
      ],
      "explanation": {
        "text": "A residual (eᵢ) is fundamentally the difference between the actual observed value of the dependent variable (Yᵢ) and the value predicted by the regression model (Ŷᵢ). The formula is eᵢ = Yᵢ - Ŷᵢ, as shown in the LaTeX visual. This value represents the error in the model's prediction for that specific observation. Options A, C, and D are incorrect calculations.",
        "step_by_step": [
          {
            "step": 1,
            "title": "Understand Observed and Predicted Values",
            "content": "In regression, Yᵢ is the actual value we recorded for the dependent variable for observation 'i'. Ŷᵢ (read as 'Y-hat sub i') is the value that our regression model predicts for Yᵢ based on its independent variables."
          },
          {
            "step": 2,
            "title": "Calculate the Difference (Error)",
            "content": "The residual is simply the error of our prediction. It's how much our actual observed value differs from what our model predicted. So, we subtract the predicted value from the observed value: eᵢ = Yᵢ - Ŷᵢ."
          }
        ],
        "interpretation": "A residual quantifies how well the model fit a particular data point; a smaller absolute residual indicates a better fit for that observation.",
        "business_context": "In a model predicting customer churn, if a customer actually churned (Y=1) but the model predicted they wouldn't (Ŷ=0), the residual (1-0=1) indicates a significant prediction error, prompting further investigation."
      },
      "difficulty_level": 1,
      "source_flashcard_id": "DAA_lec_3_6",
      "tags": [
        "Residuals",
        "Regression Analysis",
        "Formula",
        "Error"
      ],
      "visual_type": "None",
      "visual_code": "",
      "alt_text": ""
    },
    {
      "type": "mcq",
      "question_text": "Which of the following techniques are commonly used to help identify vertical outliers by normalizing residual values?",
      "question_visual": null,
      "question_visual_type": "None",
      "options": {
        "A": "Raw residuals",
        "B": "Standardized residuals",
        "C": "Studentized residuals",
        "D": "Adjusted R-squared"
      },
      "correct_answer": [
        "B"
      ],
      "explanation": {
        "text": "While raw residuals show the direct difference, **Standardized residuals** are commonly used to identify vertical outliers by dividing each residual by an estimate of its standard deviation. This normalizes them, making it easier to compare residuals across different observations and identify those that are unusually large (e.g., typically beyond ±2 or ±3 standard deviations). Studentized residuals are a more refined version but for Level 1, standardized residuals are the direct answer here. Adjusted R-squared (D) is a measure of model fit, not an outlier identification tool.",
        "step_by_step": [],
        "interpretation": "Normalizing residuals allows us to easily spot extreme errors, as they will stand out against a common scale.",
        "business_context": "In quality control, if a model predicts product defects, using standardized residuals helps quickly flag products with unusually high defect rates that warrant immediate inspection, regardless of the product type or production batch size."
      },
      "difficulty_level": 1,
      "source_flashcard_id": "DAA_lec_3_6",
      "tags": [
        "Outliers",
        "Residuals",
        "Standardized Residuals",
        "Identification"
      ],
      "visual_type": "None",
      "visual_code": "",
      "alt_text": ""
    },
    {
      "type": "mcq",
      "question_text": "A common mistake when dealing with outliers in regression analysis is:",
      "question_visual": null,
      "question_visual_type": "None",
      "options": {
        "A": "Ignoring them completely.",
        "B": "Automatically deleting them without investigation.",
        "C": "Investigating their cause before deciding on a course of action.",
        "D": "Using them to adjust the R-squared value."
      },
      "correct_answer": [
        "B"
      ],
      "explanation": {
        "text": "A common and significant mistake is to automatically delete outliers without first investigating their cause. Outliers can represent crucial, rare events, data entry errors, or unique phenomena that offer valuable business insights. Deleting them without understanding why they occurred can lead to models that lack realism or miss important strategic information. Investigating their cause (C) is the correct approach. Ignoring them (A) is also a mistake, but automatic deletion is a specific action that often leads to loss of information. Option D is irrelevant.",
        "step_by_step": [],
        "interpretation": "Outliers are not always 'bad data'; they can be 'interesting data' that tells us something important about the underlying process.",
        "business_context": "If a pharmaceutical company sees an outlier in drug trial data (e.g., an unexpected severe side effect), automatically removing it would be a critical mistake, as it could mask a serious safety issue. Proper investigation is paramount."
      },
      "difficulty_level": 1,
      "source_flashcard_id": "DAA_lec_3_6",
      "tags": [
        "Outliers",
        "Common Mistakes",
        "Regression Analysis",
        "Data Cleaning"
      ],
      "visual_type": "None",
      "visual_code": "",
      "alt_text": ""
    },
    {
      "type": "mcq",
      "question_text": "If an observation in a regression model has an unusually large positive residual, what does this indicate?",
      "question_visual": null,
      "question_visual_type": "None",
      "options": {
        "A": "The observed Y value was much lower than the model predicted.",
        "B": "The observed Y value was much higher than the model predicted.",
        "C": "The independent variable (X) for that observation was unusually small.",
        "D": "The model perfectly predicted the Y value for that observation."
      },
      "correct_answer": [
        "B"
      ],
      "explanation": {
        "text": "A residual is calculated as eᵢ = Yᵢ - Ŷᵢ. If the residual is unusually large and positive, it means that Yᵢ (the observed value) was significantly greater than Ŷᵢ (the predicted value). In other words, the model underestimated the actual outcome. Option A would result in a large negative residual. Options C and D are incorrect interpretations of a large positive residual.",
        "step_by_step": [
          {
            "step": 1,
            "title": "Recall the Residual Formula",
            "content": "The residual (eᵢ) is defined as the difference between the observed value (Yᵢ) and the predicted value (Ŷᵢ): eᵢ = Yᵢ - Ŷᵢ."
          },
          {
            "step": 2,
            "title": "Interpret a Large Positive Residual",
            "content": "For eᵢ to be a large positive number, Yᵢ must be significantly larger than Ŷᵢ. If Yᵢ - Ŷᵢ > 0, and that difference is large, it means the actual outcome was much higher than the model's prediction."
          }
        ],
        "interpretation": "A large positive residual means the model 'missed' significantly on the low side; the actual event was much more intense or occurred to a greater extent than expected.",
        "business_context": "If a model predicts sales of $100,000, but actual sales are $500,000, the large positive residual of $400,000 indicates a significant underestimation, which could point to a highly successful but unmodeled marketing event or a competitor's unexpected failure."
      },
      "difficulty_level": 1,
      "source_flashcard_id": "DAA_lec_3_6",
      "tags": [
        "Residuals",
        "Interpretation",
        "Outliers",
        "Prediction Error"
      ],
      "visual_type": "None",
      "visual_code": "",
      "alt_text": ""
    },
    {
      "type": "mcq",
      "question_text": "In regression diagnostics, what does 'leverage' primarily quantify about an observation?",
      "question_visual": null,
      "question_visual_type": "None",
      "options": {
        "A": "How much the residual of the observation deviates from zero.",
        "B": "How far an observation's predictor values are from the mean of all predictor values.",
        "C": "The change in R-squared if the observation is removed.",
        "D": "The magnitude of the auto-correlation in the residuals."
      },
      "correct_answer": [
        "B"
      ],
      "explanation": {
        "text": "Leverage, often measured by hat values (hᵢᵢ), specifically quantifies how unusual an observation's predictor (X) values are compared to the average predictor values in the dataset. It indicates an observation's potential to 'pull' the regression line.",
        "step_by_step": [],
        "interpretation": "High leverage means the observation's X-values are extreme, giving it a strong potential to influence the model.",
        "business_context": "In a marketing spend model, a month with exceptionally high advertising expenditure compared to other months would have high leverage."
      },
      "difficulty_level": 1,
      "source_flashcard_id": "DAA_lec_3_7",
      "tags": [
        "Leverage",
        "Regression Diagnostics",
        "Hat Values"
      ],
      "visual_type": "None",
      "visual_code": "",
      "alt_text": ""
    },
    {
      "type": "mcq",
      "question_text": "Which of the following measures quantifies how much the regression coefficients would change if a particular observation were removed?",
      "question_visual": null,
      "question_visual_type": "None",
      "options": {
        "A": "Standardized Residual",
        "B": "Variance Inflation Factor (VIF)",
        "C": "Cook's Distance",
        "D": "Durbin-Watson Statistic"
      },
      "correct_answer": [
        "C"
      ],
      "explanation": {
        "text": "Cook's Distance (Dᵢ) is a primary measure of influence. It assesses the overall impact of an observation on the estimated regression coefficients by calculating how much the coefficients would shift if that observation were excluded from the model. High Cook's Distance indicates high influence.",
        "step_by_step": [],
        "interpretation": "A large Cook's Distance suggests that the point is highly influential and its removal would significantly alter the model's parameters.",
        "business_context": "Identifying observations with high Cook's Distance is crucial to ensure that the model's conclusions are not overly dependent on a few data points, which could lead to unstable business decisions."
      },
      "difficulty_level": 1,
      "source_flashcard_id": "DAA_lec_3_7",
      "tags": [
        "Influence",
        "Cook's Distance",
        "Regression Diagnostics"
      ],
      "visual_type": "None",
      "visual_code": "",
      "alt_text": ""
    },
    {
      "type": "mcq",
      "question_text": "An observation is considered 'influential' in regression analysis when it has a significant impact on the estimated regression coefficients. What two factors typically combine to make an observation highly influential?",
      "question_visual": null,
      "question_visual_type": "None",
      "options": {
        "A": "Low leverage and small residual",
        "B": "High R-squared and low p-value",
        "C": "High leverage and large residual",
        "D": "Low variance and high bias"
      },
      "correct_answer": [
        "C"
      ],
      "explanation": {
        "text": "Influence is a combined effect. An observation becomes highly influential when it has both high leverage (its predictor values are extreme) and a large residual (it deviates significantly from the trend established by other data points). This combination means it has the potential to pull the line, and it actually does.",
        "step_by_step": [],
        "interpretation": "Think of a seesaw: leverage is how far you sit from the center, and a large residual is like your weight. Sitting far out (high leverage) and being heavy (large residual) will cause a big change (high influence) in the seesaw's tilt.",
        "business_context": "A data point representing an unusual event (e.g., a major holiday sale) with both extreme marketing spend and sales figures that don't fit the usual pattern would be highly influential."
      },
      "difficulty_level": 1,
      "source_flashcard_id": "DAA_lec_3_7",
      "tags": [
        "Influence",
        "Leverage",
        "Residuals",
        "Regression Diagnostics"
      ],
      "visual_type": "None",
      "visual_code": "",
      "alt_text": ""
    },
    {
      "type": "mcq",
      "question_text": "A common mistake in regression diagnostics is to assume that all high-leverage points are also highly influential. Why is this assumption incorrect?",
      "question_visual": null,
      "question_visual_type": "None",
      "options": {
        "A": "High-leverage points only affect the intercept, not the slope.",
        "B": "Influence depends only on the size of the residual, not leverage.",
        "C": "A high-leverage point with a small residual may not be highly influential.",
        "D": "High-leverage points are always removed from the dataset, so they can't be influential."
      },
      "correct_answer": [
        "C"
      ],
      "explanation": {
        "text": "Influence requires both high leverage and a large residual. A high-leverage point (extreme X-value) that happens to align well with the overall trend (i.e., has a small residual) will not significantly alter the regression line and therefore has low influence. It has the potential, but it's not 'pulling' the line.",
        "step_by_step": [],
        "interpretation": "An extreme X-value doesn't necessarily mean it's an outlier in terms of fitting the model. If it fits the model well despite its extreme X-value, its influence is minimal.",
        "business_context": "If a company has a record-breaking advertising spend one month (high leverage), but sales perfectly match the predicted trend given that spend, it's not influential, as it confirms the existing relationship."
      },
      "difficulty_level": 1,
      "source_flashcard_id": "DAA_lec_3_7",
      "tags": [
        "Leverage",
        "Influence",
        "Common Mistakes",
        "Regression Diagnostics"
      ],
      "visual_type": "None",
      "visual_code": "",
      "alt_text": ""
    },
    {
      "type": "mcq",
      "question_text": "What is the primary difference between 'leverage' and 'influence' in the context of regression diagnostics?",
      "question_visual": null,
      "question_visual_type": "None",
      "options": {
        "A": "Leverage measures the error in prediction, while influence measures model fit.",
        "B": "Leverage is the potential for an observation to affect the regression line, while influence is the actual effect it has.",
        "C": "Leverage applies only to predictor variables, while influence applies only to response variables.",
        "D": "Leverage is quantified by Cook's Distance, while influence is quantified by hat values."
      },
      "correct_answer": [
        "B"
      ],
      "explanation": {
        "text": "Leverage quantifies an observation's potential to pull the regression line due to its extreme predictor values. Influence, on the other hand, quantifies the actual change in regression coefficients if that observation were removed. Influence is the realized impact, whereas leverage is the capability to impact.",
        "step_by_step": [],
        "interpretation": "Leverage is like having a strong position, while influence is actually exerting that strength to make a change.",
        "business_context": "Understanding this distinction helps analysts differentiate between data points that are simply unusual in their inputs (high leverage) versus those that fundamentally alter the business insights derived from the model (high influence)."
      },
      "difficulty_level": 1,
      "source_flashcard_id": "DAA_lec_3_7",
      "tags": [
        "Leverage",
        "Influence",
        "Regression Diagnostics"
      ],
      "visual_type": "None",
      "visual_code": "",
      "alt_text": ""
    },
    {
      "type": "mcq",
      "question_text": "What is auto-correlation in the context of regression analysis?",
      "question_visual": null,
      "question_visual_type": "None",
      "options": {
        "A": "When predictor variables are highly correlated with each other.",
        "B": "When the error terms (residuals) of a regression model are correlated across different time periods.",
        "C": "When the response variable is correlated with itself over time.",
        "D": "When the regression model includes too many predictor variables."
      },
      "correct_answer": [
        "B"
      ],
      "explanation": {
        "text": "Auto-correlation, also known as serial correlation, occurs when the error terms (residuals) from a regression model are not independent but are correlated with each other across different time points. This means that the error at one point in time provides information about the error at another point.",
        "step_by_step": [],
        "interpretation": "Essentially, your model's mistakes are not random; they follow a pattern over time, indicating there's something systematic your model is missing.",
        "business_context": "If a sales forecasting model consistently over-predicts for a week and then under-predicts for the next, this indicates auto-correlation in its prediction errors."
      },
      "difficulty_level": 1,
      "source_flashcard_id": "DAA_lec_3_8",
      "tags": [
        "Auto-correlation",
        "Serial Correlation",
        "Regression Analysis",
        "Error Terms"
      ],
      "visual_type": "None",
      "visual_code": "",
      "alt_text": ""
    },
    {
      "type": "mcq",
      "question_text": "Auto-correlation violates which fundamental assumption of Ordinary Least Squares (OLS) regression?",
      "question_visual": null,
      "question_visual_type": "None",
      "options": {
        "A": "The error terms have constant variance (homoscedasticity).",
        "B": "The relationship between predictors and response is linear.",
        "C": "The error terms are independent of each other.",
        "D": "The predictor variables are not perfectly correlated (no multicollinearity)."
      },
      "correct_answer": [
        "C"
      ],
      "explanation": {
        "text": "A core assumption of OLS regression is that the error terms are independent. Auto-correlation directly violates this assumption by indicating that the error terms are correlated over time or across observations, which is particularly common in time series data.",
        "step_by_step": [],
        "interpretation": "If errors are dependent, it means knowing one error tells you something about the next, which breaks the idea that each observation is an independent piece of information for the model.",
        "business_context": "If a financial model's errors are dependent, it means the model isn't capturing all the relevant information, and its reliability for predicting future stock prices is compromised."
      },
      "difficulty_level": 1,
      "source_flashcard_id": "DAA_lec_3_8",
      "tags": [
        "Auto-correlation",
        "OLS Assumptions",
        "Independent Errors"
      ],
      "visual_type": "None",
      "visual_code": "",
      "alt_text": ""
    },
    {
      "type": "mcq",
      "question_text": "Which of the following is a common cause of auto-correlation in regression residuals?",
      "question_visual": null,
      "question_visual_type": "None",
      "options": {
        "A": "Including too many independent variables.",
        "B": "Omitting an important predictor variable that follows a time-series pattern.",
        "C": "Having a very small sample size.",
        "D": "Using a logarithmic transformation on the response variable."
      },
      "correct_answer": [
        "B"
      ],
      "explanation": {
        "text": "One of the most frequent causes of auto-correlation is the omission of an important variable that itself has a time-series pattern. If such a variable is left out, its influence is absorbed into the error term, causing the errors to exhibit a pattern over time.",
        "step_by_step": [],
        "interpretation": "The model's 'mistakes' aren't random because they're systematically trying to account for missing information, often related to time-dependent factors.",
        "business_context": "A model forecasting electricity consumption might show auto-correlation if it omits a seasonal variable like 'temperature,' as temperature has a strong time-series pattern and affects consumption."
      },
      "difficulty_level": 1,
      "source_flashcard_id": "DAA_lec_3_8",
      "tags": [
        "Auto-correlation",
        "Causes",
        "Omitted Variables"
      ],
      "visual_type": "None",
      "visual_code": "",
      "alt_text": ""
    },
    {
      "type": "mcq",
      "question_text": "When building a time series regression model, using a 'lagged dependent variable' as a predictor can sometimes lead to auto-correlation. What does 'lagged dependent variable' mean?",
      "question_visual": null,
      "question_visual_type": "None",
      "options": {
        "A": "The response variable from a previous time period.",
        "B": "A predictor variable that is slow to change over time.",
        "C": "The response variable that is used without any transformation.",
        "D": "A predictor variable that is highly correlated with other predictors."
      },
      "correct_answer": [
        "A"
      ],
      "explanation": {
        "text": "A lagged dependent variable is simply the response variable from a previous time period (e.g., sales today are predicted using sales yesterday). Including such a variable can introduce auto-correlation because the current error term might be correlated with past error terms through the lagged dependent variable.",
        "step_by_step": [],
        "interpretation": "If Y(t) depends on Y(t-1), and the error at t-1 affects Y(t-1), then it can indirectly affect the error at t.",
        "business_context": "In retail, 'sales today' might be highly dependent on 'sales yesterday.' Including 'sales yesterday' as a predictor can be useful but also a source of auto-correlation if not handled carefully."
      },
      "difficulty_level": 1,
      "source_flashcard_id": "DAA_lec_3_8",
      "tags": [
        "Auto-correlation",
        "Lagged Dependent Variables",
        "Time Series"
      ],
      "visual_type": "None",
      "visual_code": "",
      "alt_text": ""
    },
    {
      "type": "mcq",
      "question_text": "What does it mean if the error terms in a regression model are positively auto-correlated?",
      "question_visual": null,
      "question_visual_type": "None",
      "options": {
        "A": "Large positive errors tend to follow large negative errors.",
        "B": "Large positive errors tend to follow large positive errors, and large negative errors tend to follow large negative errors.",
        "C": "The errors are randomly distributed with no discernible pattern.",
        "D": "The errors are consistently increasing over time."
      },
      "correct_answer": [
        "B"
      ],
      "explanation": {
        "text": "Positive auto-correlation means that a positive error term is likely to be followed by another positive error term, and a negative error term is likely to be followed by another negative error term. This creates 'runs' or 'bunches' of errors with the same sign, indicating a systematic pattern in the model's mistakes.",
        "step_by_step": [],
        "interpretation": "The model is consistently under-predicting or over-predicting for several consecutive periods, rather than making random errors.",
        "business_context": "If a weather prediction model has positive auto-correlation, it might consistently predict higher temperatures than actual for several days, then consistently lower for several days, rather than having random errors day-to-day."
      },
      "difficulty_level": 1,
      "source_flashcard_id": "DAA_lec_3_8",
      "tags": [
        "Auto-correlation",
        "Error Terms",
        "Positive Auto-correlation"
      ],
      "visual_type": "None",
      "visual_code": "",
      "alt_text": ""
    },
    {
      "type": "mcq",
      "question_text": "If auto-correlation is present in a regression model, how does it affect the Ordinary Least Squares (OLS) estimators of the regression coefficients?",
      "question_visual": null,
      "question_visual_type": "None",
      "options": {
        "A": "They become biased and inconsistent.",
        "B": "They remain unbiased but become inefficient.",
        "C": "They become more efficient and unbiased.",
        "D": "They are unaffected, but the R-squared value decreases."
      },
      "correct_answer": [
        "B"
      ],
      "explanation": {
        "text": "When auto-correlation is present, OLS estimators remain unbiased (on average, they will be correct), but they lose their efficiency. This means they are no longer the Best Linear Unbiased Estimators (BLUE), and there are other estimators that could provide smaller variance.",
        "step_by_step": [],
        "interpretation": "The model's coefficient estimates might still be correct 'on average,' but they are less precise than they could be, making it harder to trust their exact values.",
        "business_context": "If a company models the impact of marketing spend, the estimated coefficient for spend might be correct, but auto-correlation means there's a better way to estimate it with less uncertainty, leading to more reliable resource allocation decisions."
      },
      "difficulty_level": 1,
      "source_flashcard_id": "DAA_lec_3_9",
      "tags": [
        "Auto-correlation",
        "OLS Estimators",
        "Efficiency",
        "BLUE"
      ],
      "visual_type": "None",
      "visual_code": "",
      "alt_text": ""
    },
    {
      "type": "mcq",
      "question_text": "What is the typical consequence of auto-correlation on the standard errors of OLS regression coefficients?",
      "question_visual": null,
      "question_visual_type": "None",
      "options": {
        "A": "They are typically overestimated.",
        "B": "They are typically underestimated.",
        "C": "They remain accurate and unbiased.",
        "D": "They become zero, indicating perfect precision."
      },
      "correct_answer": [
        "B"
      ],
      "explanation": {
        "text": "A critical consequence of auto-correlation is that the standard errors of the OLS coefficients are typically underestimated. This makes the estimators appear more precise than they actually are.",
        "step_by_step": [],
        "interpretation": "Underestimated standard errors mean that your confidence intervals for the coefficients will be too narrow, and your p-values will be too small, leading to an exaggerated sense of precision and statistical significance.",
        "business_context": "A financial analyst might conclude that a stock's past performance (predictor) has a highly significant impact on its future performance (response) due to a tiny p-value. If auto-correlation is present, this significance is likely overstated, leading to risky investment decisions."
      },
      "difficulty_level": 1,
      "source_flashcard_id": "DAA_lec_3_9",
      "tags": [
        "Auto-correlation",
        "Standard Errors",
        "OLS Consequences"
      ],
      "visual_type": "None",
      "visual_code": "",
      "alt_text": ""
    },
    {
      "type": "mcq",
      "question_text": "How does auto-correlation generally affect the p-values associated with hypothesis tests for regression coefficients?",
      "question_visual": null,
      "question_visual_type": "None",
      "options": {
        "A": "P-values become larger, making it harder to reject the null hypothesis.",
        "B": "P-values become smaller, making it easier to incorrectly reject the null hypothesis.",
        "C": "P-values remain unchanged, as they are not affected by auto-correlation.",
        "D": "P-values can either increase or decrease, depending on the type of auto-correlation."
      },
      "correct_answer": [
        "B"
      ],
      "explanation": {
        "text": "Because auto-correlation leads to underestimated standard errors, the calculated t-statistics (which use standard errors in their denominator) become inflated. This, in turn, results in smaller p-values than they should be, making it easier to incorrectly conclude that a predictor is statistically significant.",
        "step_by_step": [
          {
            "step": 1,
            "title": "Impact on Standard Errors",
            "content": "Auto-correlation typically causes the standard errors of regression coefficients to be underestimated. This means the perceived variability of the coefficient estimates is lower than their true variability."
          },
          {
            "step": 2,
            "title": "Impact on T-statistics",
            "content": "The t-statistic for a coefficient is calculated as (coefficient estimate / standard error). If the standard error is underestimated, the t-statistic will be artificially inflated (larger in magnitude)."
          },
          {
            "step": 3,
            "title": "Impact on P-values",
            "content": "Larger t-statistics lead to smaller p-values. A smaller p-value makes it appear that the coefficient is more statistically significant than it actually is, increasing the risk of a Type I error (false positive)."
          }
        ],
        "interpretation": "The model gives a false sense of confidence in its predictors, leading to potentially flawed conclusions about which factors are truly important.",
        "business_context": "A marketing team might mistakenly believe a specific ad campaign has a statistically significant impact on sales, based on a low p-value. If auto-correlation is present, this 'significance' is likely spurious, and resources might be misallocated to ineffective campaigns."
      },
      "difficulty_level": 1,
      "source_flashcard_id": "DAA_lec_3_9",
      "tags": [
        "Auto-correlation",
        "P-values",
        "Hypothesis Testing",
        "Standard Errors"
      ],
      "visual_type": "None",
      "visual_code": "",
      "alt_text": ""
    },
    {
      "type": "mcq",
      "question_text": "Which visual diagnostic tool is commonly used to detect auto-correlation in the residuals of a time series regression model?",
      "question_visual": null,
      "question_visual_type": "None",
      "options": {
        "A": "Normal Q-Q Plot",
        "B": "Scatter plot of residuals versus fitted values",
        "C": "Histogram of residuals",
        "D": "Plot of residuals versus time (or observation order)"
      },
      "correct_answer": [
        "D"
      ],
      "explanation": {
        "text": "A plot of residuals against time (or the order in which observations were collected) is the most direct visual tool for detecting auto-correlation. If a systematic pattern, such as a wave-like trend or long runs of positive or negative residuals, is observed, it indicates auto-correlation.",
        "step_by_step": [],
        "interpretation": "Instead of random scatter around zero, you'd see a pattern in the errors over time, revealing the underlying dependency.",
        "business_context": "A logistics company forecasting delivery times would plot daily residual errors. If they see a pattern of positive errors (underestimating time) for a week, then negative errors (overestimating time) for the next, it suggests auto-correlation, perhaps due to unmodeled weekly traffic patterns."
      },
      "difficulty_level": 1,
      "source_flashcard_id": "DAA_lec_3_9",
      "tags": [
        "Auto-correlation",
        "Residual Plots",
        "Time Series",
        "Diagnostics"
      ],
      "visual_type": "None",
      "visual_code": "",
      "alt_text": ""
    },
    {
      "type": "mca",
      "question_text": "When visually inspecting a residual plot (residuals vs. time) for auto-correlation, which of the following patterns would indicate the presence of auto-correlation? (Select all that apply)",
      "question_visual": {
        "type": "matplotlib",
        "plot_type": "residual_plot_time_series",
        "params": {
          "residuals": [
            0.5,
            0.8,
            0.3,
            -0.2,
            -0.7,
            -0.9,
            -0.4,
            0.1,
            0.6,
            0.9,
            0.4,
            -0.1,
            -0.6,
            -0.8
          ],
          "x_label": "Time Period",
          "y_label": "Residual",
          "title": "Residuals Over Time",
          "hline": 0
        }
      },
      "question_visual_type": "matplotlib",
      "options": {
        "A": "A wave-like or cyclical pattern in the residuals.",
        "B": "Consecutive runs of residuals with the same sign (e.g., several positive residuals followed by several negative residuals).",
        "C": "A completely random scatter of residuals around zero, with no discernible pattern.",
        "D": "Residuals that fan out from the fitted line as predicted values increase."
      },
      "correct_answer": [
        "A",
        "B"
      ],
      "explanation": {
        "text": "Auto-correlation manifests as systematic patterns in residual plots over time. Wave-like or cyclical patterns (A) clearly show errors that are dependent on previous errors. Similarly, consecutive runs of residuals with the same sign (B) indicate that the model's errors are 'sticky' and not random, suggesting positive or negative auto-correlation. A random scatter (C) indicates no auto-correlation. Residuals fanning out (D) indicate heteroscedasticity, not auto-correlation.",
        "step_by_step": [
          {
            "step": 1,
            "title": "Understanding Auto-correlation",
            "content": "Auto-correlation means that the error at one point in time is correlated with the error at another point. This implies a non-random pattern in the residuals when plotted against time."
          },
          {
            "step": 2,
            "title": "Identifying Wave-like/Cyclical Patterns",
            "content": "If you see residuals consistently above zero for a period, then consistently below zero, and then back above, this 'wave' suggests that the model is systematically under-predicting, then over-predicting, following a cycle not captured by the model (Option A is correct)."
          },
          {
            "step": 3,
            "title": "Identifying Runs of Same-Sign Residuals",
            "content": "When several positive residuals occur consecutively, followed by several negative ones, it indicates that the error term is not independent over time. This 'stickiness' in the errors is a hallmark of auto-correlation (Option B is correct)."
          },
          {
            "step": 4,
            "title": "Distinguishing from Other Issues",
            "content": "Option C describes ideal residuals (no auto-correlation). Option D describes heteroscedasticity, where the variance of residuals changes with the predicted values, which is a different diagnostic concern."
          }
        ],
        "interpretation": "These visual patterns are strong indicators that your model is missing a time-dependent component or has an incorrect functional form, leading to predictable errors.",
        "business_context": "If a company's demand forecast model shows a wave-like pattern in its weekly errors, it suggests an uncaptured seasonal trend, like monthly promotions or holiday spikes, that needs to be incorporated into the model for better accuracy."
      },
      "difficulty_level": 1,
      "source_flashcard_id": "DAA_lec_3_9",
      "tags": [
        "Auto-correlation",
        "Residual Plots",
        "Visual Detection",
        "Time Series"
      ],
      "visual_type": "None",
      "visual_code": "",
      "alt_text": ""
    },
    {
      "type": "mcq",
      "question_text": "In the context of the Durbin-Watson (DW) statistic, what does a value approximately equal to 2 (DW ≈ 2) typically indicate?",
      "question_visual": null,
      "question_visual_type": "None",
      "options": {
        "A": "Significant positive auto-correlation",
        "B": "Significant negative auto-correlation",
        "C": "No first-order auto-correlation",
        "D": "Presence of heteroscedasticity"
      },
      "correct_answer": [
        "C"
      ],
      "explanation": {
        "text": "The Durbin-Watson statistic ranges from 0 to 4. A value close to 2 suggests that the residuals are independent and there is no first-order auto-correlation. Option D is incorrect as heteroscedasticity is tested by other diagnostics, not the DW statistic.",
        "step_by_step": [],
        "interpretation": "A DW statistic near 2 indicates that the assumption of independent errors in a regression model is likely met, at least for first-order dependencies.",
        "business_context": "When a forecasting model shows a DW near 2, it gives confidence that past prediction errors are not systematically influencing future errors, leading to more reliable forecasts."
      },
      "difficulty_level": 1,
      "source_flashcard_id": "DAA_lec_3_10",
      "tags": [
        "Durbin-Watson Statistic",
        "Auto-correlation",
        "Regression Diagnostics",
        "Residuals"
      ],
      "visual_type": "None",
      "visual_code": "",
      "alt_text": ""
    },
    {
      "type": "mcq",
      "question_text": "What is the typical range of values for the Durbin-Watson (DW) statistic?",
      "question_visual": null,
      "question_visual_type": "None",
      "options": {
        "A": "-1 to 1",
        "B": "0 to 1",
        "C": "0 to 4",
        "D": "1 to 3"
      },
      "correct_answer": [
        "C"
      ],
      "explanation": {
        "text": "The Durbin-Watson statistic is constructed such that its value will always fall within the range of 0 to 4. This range helps in its interpretation regarding positive, negative, or no auto-correlation. Options A, B, and D represent incorrect ranges for the DW statistic.",
        "step_by_step": [],
        "interpretation": "Understanding the range of the DW statistic is foundational for interpreting its calculated value in regression diagnostics.",
        "business_context": "Knowing the possible range helps analysts quickly identify if a calculated DW value is plausible or if there might be a calculation error."
      },
      "difficulty_level": 1,
      "source_flashcard_id": "DAA_lec_3_10",
      "tags": [
        "Durbin-Watson Statistic",
        "Auto-correlation"
      ],
      "visual_type": "None",
      "visual_code": "",
      "alt_text": ""
    },
    {
      "type": "mcq",
      "question_text": "The Durbin-Watson (DW) statistic is primarily used as a formal test for which specific econometric issue in regression analysis?",
      "question_visual": null,
      "question_visual_type": "None",
      "options": {
        "A": "Multicollinearity between independent variables",
        "B": "Heteroscedasticity in residuals",
        "C": "First-order auto-correlation in residuals",
        "D": "Non-normality of residuals"
      },
      "correct_answer": [
        "C"
      ],
      "explanation": {
        "text": "The Durbin-Watson statistic is specifically designed to detect the presence of first-order auto-correlation, which is a common problem in time-series data. Options A, B, and D are incorrect as they relate to other regression diagnostic issues that are typically assessed using different statistical tests (e.g., VIF for multicollinearity, Breusch-Pagan for heteroscedasticity).",
        "step_by_step": [],
        "interpretation": "The primary role of the DW test is to check the assumption of independent errors, especially for consecutive observations.",
        "business_context": "In financial time-series modeling, ensuring errors are not auto-correlated is crucial for valid inference, making the DW test a standard initial check."
      },
      "difficulty_level": 1,
      "source_flashcard_id": "DAA_lec_3_10",
      "tags": [
        "Durbin-Watson Statistic",
        "Auto-correlation",
        "Regression Diagnostics",
        "Time Series",
        "Residuals"
      ],
      "visual_type": "None",
      "visual_code": "",
      "alt_text": ""
    },
    {
      "type": "mcq",
      "question_text": "A Durbin-Watson (DW) statistic value significantly less than 2 (e.g., < 1.5) suggests the presence of which type of auto-correlation?",
      "question_visual": null,
      "question_visual_type": "None",
      "options": {
        "A": "No auto-correlation",
        "B": "Positive auto-correlation",
        "C": "Negative auto-correlation",
        "D": "Higher-order auto-correlation"
      },
      "correct_answer": [
        "B"
      ],
      "explanation": {
        "text": "When the Durbin-Watson statistic is significantly less than 2, it indicates positive first-order auto-correlation, meaning that consecutive residuals tend to be similar in sign. Option C is incorrect as negative auto-correlation is suggested by values significantly greater than 2.",
        "step_by_step": [],
        "interpretation": "A low DW value signals that an over-prediction tends to be followed by another over-prediction, or an under-prediction by another under-prediction.",
        "business_context": "If a sales forecasting model consistently overestimates sales for several periods, a low DW statistic would confirm this pattern, prompting adjustments to the model."
      },
      "difficulty_level": 1,
      "source_flashcard_id": "DAA_lec_3_10",
      "tags": [
        "Durbin-Watson Statistic",
        "Auto-correlation",
        "Regression Diagnostics"
      ],
      "visual_type": "None",
      "visual_code": "",
      "alt_text": ""
    },
    {
      "type": "mca",
      "question_text": "Which of the following statements are TRUE regarding the interpretation and application of the Durbin-Watson (DW) statistic? (Select all that apply)",
      "question_visual": null,
      "question_visual_type": "None",
      "options": {
        "A": "A DW value close to 2 indicates an absence of first-order auto-correlation.",
        "B": "The DW statistic should always be compared to critical values (d_L, d_U) for proper significance testing.",
        "C": "A DW value significantly greater than 2 suggests positive auto-correlation.",
        "D": "The Durbin-Watson test is designed to detect all orders of auto-correlation."
      },
      "correct_answer": [
        "A",
        "B"
      ],
      "explanation": {
        "text": "Statement A is true: A DW value near 2 indicates no first-order auto-correlation. Statement B is true: Proper interpretation of the DW statistic requires comparing the calculated value to specific critical values (d_L and d_U) from a Durbin-Watson table, which depend on sample size and number of predictors, not just a simple cutoff. Statement C is false: A DW value significantly greater than 2 suggests negative auto-correlation, not positive. Statement D is false: The DW test is primarily designed to detect only first-order auto-correlation.",
        "step_by_step": [],
        "interpretation": "Accurate interpretation of the DW statistic requires understanding its range, what specific type of auto-correlation it tests for, and the necessity of using critical values for statistical inference.",
        "business_context": "Misinterpreting the DW statistic can lead to incorrect conclusions about model validity, potentially resulting in poor business decisions based on flawed predictions."
      },
      "difficulty_level": 1,
      "source_flashcard_id": "DAA_lec_3_10",
      "tags": [
        "Durbin-Watson Statistic",
        "Auto-correlation",
        "Regression Diagnostics",
        "Common Mistakes",
        "Hypothesis Testing"
      ],
      "visual_type": "None",
      "visual_code": "",
      "alt_text": ""
    }
  ]
}